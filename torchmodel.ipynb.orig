{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
<<<<<<< HEAD
=======
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 14\n",
    "        self.test_batch_size = 14\n",
    "        self.epochs = 10\n",
    "        self.lr = 0.02\n",
    "        self.seed = 1\n",
    "        self.log_interval = 1 # Log info at each batch\n",
    "        self.precision_fractional = 3\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "_ = torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/home/h/houruomu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/h/houruomu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/h/houruomu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/h/houruomu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/h/houruomu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/h/houruomu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/h/houruomu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/h/houruomu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/h/houruomu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/h/houruomu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/h/houruomu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/h/houruomu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tf_encrypted:Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/h/houruomu/.local/lib/python3.6/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n"
=======
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/souhail/.local/lib/python3.7/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_2.0.0.so'\n"
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "WARNING:tensorflow:From /home/h/houruomu/.local/lib/python3.6/site-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/h/houruomu/.local/lib/python3.6/site-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
=======
      "WARNING:tensorflow:From /home/souhail/.local/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "def connect_to_workers(n_workers):\n",
    "    return [\n",
    "        sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n",
    "        for i in range(n_workers)\n",
    "    ]\n",
    "def connect_to_crypto_provider():\n",
    "    return sy.VirtualWorker(hook, id=\"crypto_provider\")\n",
    "\n",
    "workers = connect_to_workers(n_workers=2)\n",
    "crypto_provider = connect_to_crypto_provider()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 4,
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def getSamples(filename):\n",
    "    data = pd.read_csv(filename, sep='\\t')\n",
    "    return data.values[:,1:].transpose()\n",
    "\n",
    "data1 = getSamples(\"GSE2034-Normal-train.txt\")\n",
    "data2 = getSamples(\"GSE2034-Tumor-train.txt\")\n",
    "\n",
    "data1Label = np.zeros(len(data1)).reshape((-1, 1))\n",
    "data2Label = np.ones(len(data2)).reshape((-1, 1))\n",
    "x = np.concatenate((data1, data2))\n",
    "y = np.concatenate((data1Label, data2Label))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 5,
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't use the whole dataset for efficiency purpose, but feel free to increase these numbers\n",
    "n_train_items = 181\n",
    "n_test_items = 46\n",
    "\n",
    "# shuffle x and y in the same order\n",
    "# https://stackoverflow.com/questions/23289547/shuffle-two-list-at-once-with-same-order\n",
    "indices = np.arange(x.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# partition the data into training data and test data\n",
    "x_train = x[:n_train_items]\n",
    "y_train = y[:n_train_items]\n",
    "\n",
    "x_test = x[n_train_items:]\n",
    "y_test = y[n_train_items:]            "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-e6878ea60d57>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-e6878ea60d57>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    if i < n_train_items / args.batch_size\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 12634)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5b4606c5b215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprecision_fractional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_fractional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mcrypto_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrypto_provider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-10-5b4606c5b215>\u001b[0m in \u001b[0;36mget_private_data_loaders\u001b[0;34m(precision_fractional, workers, crypto_provider)\u001b[0m\n\u001b[1;32m     27\u001b[0m     private_train_loader = [\n\u001b[1;32m     28\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0msecret_share\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecret_share\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_train_items\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     ]\n",
      "\u001b[0;32m<ipython-input-10-5b4606c5b215>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m     private_train_loader = [\n\u001b[1;32m     28\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0msecret_share\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecret_share\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_train_items\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     ]\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
     ]
    }
   ],
   "source": [
    "\n",
    "def get_private_data_loaders(precision_fractional, workers, crypto_provider):\n",
    "    \n",
    "    def one_hot_of(index_tensor):#Transforms to one hot tensor\n",
    "     \n",
    "        onehot_tensor = torch.zeros(*index_tensor.shape, 2) # 2 Output classes\n",
    "        onehot_tensor = onehot_tensor.scatter(1, index_tensor.view(-1, 1), 1)\n",
    "        return onehot_tensor\n",
    "        \n",
    "    def secret_share(tensor): #Transforms to fixed precision and secret share a tensor\n",
    "\n",
    "        return (\n",
    "            tensor\n",
    "            .fix_precision(precision_fractional=precision_fractional)\n",
    "            .share(*workers, crypto_provider=crypto_provider, requires_grad=True)\n",
    "        )\n",
    "    \n",
    "    transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        x_train,\n",
    "        batch_size=args.batch_size\n",
    "    )\n",
    "\n",
    "    private_train_loader = [\n",
    "        (secret_share(data), secret_share(one_hot_of(target)))\n",
    "        for i, (data, target) in enumerate(train_loader)\n",
    "        if i < n_train_items / args.batch_size\n",
    "    ]\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        x_test,\n",
    "        batch_size=args.test_batch_size\n",
    "    )\n",
    "        \n",
    "    private_test_loader = [\n",
    "        (secret_share(data), secret_share(target.float()))\n",
    "        for i, (data, target) in enumerate(test_loader)\n",
    "        if i < n_test_items / args.test_batch_size\n",
    "    ]\n",
    "    \n",
    "    return private_train_loader, private_test_loader\n",
    "    \n",
    "    \n",
    "private_train_loader, private_test_loader = get_private_data_loaders(\n",
    "    precision_fractional=args.precision_fractional,\n",
    "    workers=workers,\n",
    "    crypto_provider=crypto_provider\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 4,
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 12634\n",
    "\n",
    "class Res1d(nn.Module):\n",
    "    # the conv layers\n",
    "    def __init__(self, inSize, outSize, kernel=(3,), strides=1,):\n",
    "        super(Res1d, self).__init__()\n",
    "        # hard-coded to do the padding correctly\n",
    "        if inSize in (16,64,128,512) and strides is 2:\n",
    "            pding = 0\n",
    "        else:\n",
    "            pding = 1\n",
    "        self.l1 = nn.Conv1d(inSize, outSize, kernel, stride=strides, padding=pding, bias=False)\n",
    "        self.l2 = nn.InstanceNorm1d(outSize)\n",
    "        \n",
    "        if strides > 1 or inSize != outSize:\n",
    "            if strides > 1:\n",
    "                self.r1 = nn.Identity()\n",
    "                self.r2 = nn.AvgPool1d(strides)\n",
    "            else:\n",
    "                self.r1 = None\n",
    "                self.r2 = None\n",
    "            self.r3 = nn.Conv1d(inSize, outSize, 1, bias=False)\n",
    "            self.r4 = nn.InstanceNorm1d(outSize)\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        l = self.l1(x)\n",
    "        l = self.l2(l)\n",
    "        \n",
    "        if self.r1 is not None:\n",
    "            r = self.r1(x)\n",
    "            r = self.r2(r)\n",
    "            r = self.r3(r)\n",
    "            r = self.r4(r)\n",
    "        else:\n",
    "            r = self.r3(x)\n",
    "            r = self.r4(r)\n",
    "            \n",
    "        x = l + r\n",
    "        return self.relu(x)\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(dim, 64)\n",
    "        self.l2 = nn.ReLU()\n",
    "        \n",
    "        self.r1 = Res1d(1, 4, 3)\n",
    "        \n",
    "        self.r2 = Res1d(4, 8, 3)\n",
    "        self.r3 = Res1d(8, 8, 3, strides=2)\n",
    "        \n",
    "        self.r4 = Res1d(8, 16, 3)\n",
    "        self.r5 = Res1d(16, 16, 3, strides=2)\n",
    "        \n",
    "        self.r6 = Res1d(16, 32, 3)\n",
    "        self.r7 = Res1d(32, 32, 3, strides=2)\n",
    "        \n",
    "        self.r8 = Res1d(32, 64, 3)\n",
    "        self.r9 = Res1d(64, 64, 3, strides=2)\n",
    "        \n",
    "        self.r10 = Res1d(64, 128, 3)\n",
    "        self.r11 = Res1d(128, 128, 3, strides=2)\n",
    "        \n",
    "        self.r12 = Res1d(128, 256, 3)\n",
    "        self.r13 = Res1d(256, 256, 3, strides=2)\n",
    "        \n",
    "        self.r14 = Res1d(256, 512, 3)\n",
    "        self.r15 = Res1d(512, 512, 3, strides=2)\n",
    "        \n",
    "        self.r16 = Res1d(512, 1024, 3)\n",
    "        self.r17 = Res1d(1024, 1024, 3, strides=2)\n",
    "        \n",
    "        # size is by experiment and hardcode\n",
    "        self.lastLinear = nn.Linear(50240,32)\n",
    "        self.lastRelu = nn.ReLU()\n",
    "        self.lastAgg = nn.Linear(32,1)\n",
    "        self.lastSigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # shape is (batch, channel, time)\n",
    "        l = x\n",
    "        l = self.l2(self.l1(l))\n",
    "        \n",
    "        # conv layers should operate on time\n",
    "        r = x\n",
    "        r = self.r4(self.r3(self.r2(self.r1(r))))\n",
    "        r = self.r8(self.r7(self.r6(self.r5(r))))\n",
    "        r = self.r12(self.r11(self.r10(self.r9(r))))\n",
    "        r = self.r16(self.r15(self.r14(self.r13(r))))\n",
    "        r = self.r17(r)\n",
    "        \n",
    "        # flatten l\n",
    "        r = r.view(x.shape[0],1, -1)\n",
    "        y = torch.cat((l,r),-1)\n",
    "        y = self.lastLinear(y)\n",
    "        y = self.lastRelu(y)\n",
    "        y = self.lastAgg(y)\n",
    "        y = self.lastSigmoid(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
=======
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
   "source": [
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(device)\n",
    "net = Net().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 6,
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 1, 1])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 7,
=======
     "execution_count": 6,
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test = torch.randn(80, 1, dim).float().cuda()\n",
    "out = net(input_test).cuda()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 7,
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data into (batch, channel = 1, length=dim)\n",
    "data_torch = torch.from_numpy(x).view([-1, 1, dim]).float()\n",
    "label_torch = torch.from_numpy(y).view([-1,1,1]).float()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 8,
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 10,
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "1.0 % Trained loss =  tensor(0.0845, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2.0 % Trained loss =  tensor(0.1076, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "3.0 % Trained loss =  tensor(0.0819, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "4.0 % Trained loss =  tensor(0.0626, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "5.0 % Trained loss =  tensor(0.0395, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "6.0 % Trained loss =  tensor(0.0317, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "7.0 % Trained loss =  tensor(0.0452, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "8.0 % Trained loss =  tensor(0.0465, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "9.0 % Trained loss =  tensor(0.0422, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "10.0 % Trained loss =  tensor(0.0385, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "11.0 % Trained loss =  tensor(0.0374, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "12.0 % Trained loss =  tensor(0.0381, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "13.0 % Trained loss =  tensor(0.0396, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "14.0 % Trained loss =  tensor(0.0391, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "15.0 % Trained loss =  tensor(0.0373, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "16.0 % Trained loss =  tensor(0.0361, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "17.0 % Trained loss =  tensor(0.0373, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "18.0 % Trained loss =  tensor(0.0373, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "19.0 % Trained loss =  tensor(0.0369, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "20.0 % Trained loss =  tensor(0.0371, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "21.0 % Trained loss =  tensor(0.0366, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "22.0 % Trained loss =  tensor(0.0364, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "23.0 % Trained loss =  tensor(0.0364, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "24.0 % Trained loss =  tensor(0.0367, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "25.0 % Trained loss =  tensor(0.0370, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "26.0 % Trained loss =  tensor(0.0368, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "27.0 % Trained loss =  tensor(0.0369, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "28.0 % Trained loss =  tensor(0.0367, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "29.0 % Trained loss =  tensor(0.0358, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "30.0 % Trained loss =  tensor(0.0355, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "31.0 % Trained loss =  tensor(0.0352, grad_fn=<BinaryCrossEntropyBackward>)\n"
=======
      "1.0 % Trained loss =  tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2.0 % Trained loss =  tensor(0.5648, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "3.0 % Trained loss =  tensor(0.3351, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "4.0 % Trained loss =  tensor(0.1074, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "5.0 % Trained loss =  tensor(0.0421, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "6.0 % Trained loss =  tensor(0.0147, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "7.0 % Trained loss =  tensor(0.0081, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "8.0 % Trained loss =  tensor(0.0052, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "9.0 % Trained loss =  tensor(0.0051, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "10.0 % Trained loss =  tensor(0.0032, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "11.0 % Trained loss =  tensor(0.0024, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "12.0 % Trained loss =  tensor(0.0023, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "13.0 % Trained loss =  tensor(0.0024, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "14.0 % Trained loss =  tensor(0.0020, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "15.0 % Trained loss =  tensor(0.0018, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "16.0 % Trained loss =  tensor(0.0020, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "17.0 % Trained loss =  tensor(0.0017, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "18.0 % Trained loss =  tensor(0.0018, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "19.0 % Trained loss =  tensor(0.0015, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "20.0 % Trained loss =  tensor(0.0014, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "21.0 % Trained loss =  tensor(0.0013, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "22.0 % Trained loss =  tensor(0.0013, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "23.0 % Trained loss =  tensor(0.0011, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "24.0 % Trained loss =  tensor(0.0010, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "25.0 % Trained loss =  tensor(0.0011, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "26.0 % Trained loss =  tensor(0.0011, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "27.0 % Trained loss =  tensor(0.0010, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "28.0 % Trained loss =  tensor(0.0009, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "29.0 % Trained loss =  tensor(0.0010, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "30.0 % Trained loss =  tensor(0.0009, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "31.0 % Trained loss =  tensor(0.0009, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "32.0 % Trained loss =  tensor(0.0009, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "33.0 % Trained loss =  tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "34.0 % Trained loss =  tensor(0.0009, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "35.0 % Trained loss =  tensor(0.0008, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "36.0 % Trained loss =  tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "37.0 % Trained loss =  tensor(0.0008, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "38.0 % Trained loss =  tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "39.0 % Trained loss =  tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "40.0 % Trained loss =  tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "41.0 % Trained loss =  tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "42.0 % Trained loss =  tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "43.0 % Trained loss =  tensor(0.0006, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "44.0 % Trained loss =  tensor(0.0006, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "45.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "46.0 % Trained loss =  tensor(0.0006, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "47.0 % Trained loss =  tensor(0.0006, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "48.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "49.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "50.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "51.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "52.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "53.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "54.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "55.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "56.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "57.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "58.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "59.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "60.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "61.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "62.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "63.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "64.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "65.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "66.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "67.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "68.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "69.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "70.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "71.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "72.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "73.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "74.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "75.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "76.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "77.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "78.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "79.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "80.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "81.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "82.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "83.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "84.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "85.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "86.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "87.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "88.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "89.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "91.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "92.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "93.0 % Trained loss =  tensor(0.0002, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "94.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "95.0 % Trained loss =  tensor(0.0002, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "96.0 % Trained loss =  tensor(0.0002, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "97.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "98.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "99.0 % Trained loss =  tensor(0.0002, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "100.0 % Trained loss =  tensor(0.0002, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Finished Training\n"
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
     ]
    }
   ],
   "source": [
    "test_inputs = torch.from_numpy(x_test).view([-1, 1, dim]).float().cuda()\n",
    "test_labels = torch.from_numpy(y_test).view([-1, 1]).float().cuda()\n",
    "for batch in range(1000):  # loop over the dataset multiple times\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    indices = np.random.choice(len(x_train), size=(30))\n",
    "    inputs = x_train[indices]\n",
    "    labels = y_train[indices]\n",
<<<<<<< HEAD
    "            \n",
=======
    "    \n",
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
    "    inputs = torch.from_numpy(inputs).view([-1, 1, dim]).float().cuda()\n",
    "    labels = torch.from_numpy(labels).view([-1, 1]).float().cuda()\n",
    "        \n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs).view([-1,1]).cuda()\n",
    "    loss = criterion(outputs, labels).cuda()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if batch % 10 == 0:\n",
<<<<<<< HEAD
    "        outputs = net(test_inputs).view([-1,1]).cuda()\n",
    "        loss = criterion(outputs, test_labels).cuda()\n",
=======
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
    "        print(batch / 10 + 1, \"% Trained\", \"loss = \", loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (l1): Linear(in_features=12634, out_features=64, bias=True)\n",
       "  (l2): ReLU()\n",
       "  (r1): Res1d(\n",
       "    (l1): Conv1d(1, 4, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(1, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r2): Res1d(\n",
       "    (l1): Conv1d(4, 8, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(4, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r3): Res1d(\n",
       "    (l1): Conv1d(8, 8, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r4): Res1d(\n",
       "    (l1): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(8, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r5): Res1d(\n",
       "    (l1): Conv1d(16, 16, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(16, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r6): Res1d(\n",
       "    (l1): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(16, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r7): Res1d(\n",
       "    (l1): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r8): Res1d(\n",
       "    (l1): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r9): Res1d(\n",
       "    (l1): Conv1d(64, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r10): Res1d(\n",
       "    (l1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r11): Res1d(\n",
       "    (l1): Conv1d(128, 128, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r12): Res1d(\n",
       "    (l1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r13): Res1d(\n",
       "    (l1): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r14): Res1d(\n",
       "    (l1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r15): Res1d(\n",
       "    (l1): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r16): Res1d(\n",
       "    (l1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r17): Res1d(\n",
       "    (l1): Conv1d(1024, 1024, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (lastLinear): Linear(in_features=50240, out_features=32, bias=True)\n",
       "  (lastRelu): ReLU()\n",
       "  (lastAgg): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (lastSigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MPC learning\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 88.00 MiB (GPU 0; 14.73 GiB total capacity; 5.46 GiB already allocated; 13.88 MiB free; 335.49 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPureFrameworkTensorFoundError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    302\u001b[0m             new_args, new_kwargs, new_type, args_type = hook_args.unwrap_args_from_function(\n\u001b[0;32m--> 303\u001b[0;31m                 \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_args_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36munwrap_args_from_function\u001b[0;34m(attr, args, kwargs, return_args_type)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;31m# Try running it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36mseven_fold\u001b[0;34m(lambdas, args, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m     return (\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;31m# Last if not, rule is probably == 1 so use type to return the right transformation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mforward_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# And do this for all the args / rules provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureFrameworkTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureFrameworkTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPureFrameworkTensorFoundError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-76f8d70f0f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_torch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-3527a23acd44>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr12\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr15\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr14\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr13\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr17\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-3527a23acd44>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    194\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    195\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 196\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0mhandle_func_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# in the execute_command function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 88.00 MiB (GPU 0; 14.73 GiB total capacity; 5.46 GiB already allocated; 13.88 MiB free; 335.49 MiB cached)"
     ]
=======
     "data": {
      "text/plain": [
       "tensor([[[1.9235e-04]],\n",
       "\n",
       "        [[2.7360e-04]],\n",
       "\n",
       "        [[1.4392e-04]],\n",
       "\n",
       "        [[3.3061e-04]],\n",
       "\n",
       "        [[1.0315e-04]],\n",
       "\n",
       "        [[3.0822e-04]],\n",
       "\n",
       "        [[2.3279e-04]],\n",
       "\n",
       "        [[2.8794e-04]],\n",
       "\n",
       "        [[2.0224e-04]],\n",
       "\n",
       "        [[2.3346e-04]],\n",
       "\n",
       "        [[2.8597e-04]],\n",
       "\n",
       "        [[2.5769e-04]],\n",
       "\n",
       "        [[3.1846e-04]],\n",
       "\n",
       "        [[2.9116e-04]],\n",
       "\n",
       "        [[2.4118e-04]],\n",
       "\n",
       "        [[3.2269e-04]],\n",
       "\n",
       "        [[3.1257e-04]],\n",
       "\n",
       "        [[2.3454e-04]],\n",
       "\n",
       "        [[2.3503e-04]],\n",
       "\n",
       "        [[3.3291e-04]],\n",
       "\n",
       "        [[1.6589e-04]],\n",
       "\n",
       "        [[2.6916e-04]],\n",
       "\n",
       "        [[3.0157e-04]],\n",
       "\n",
       "        [[1.8384e-04]],\n",
       "\n",
       "        [[1.3061e-04]],\n",
       "\n",
       "        [[2.0306e-04]],\n",
       "\n",
       "        [[2.0023e-04]],\n",
       "\n",
       "        [[2.0535e-04]],\n",
       "\n",
       "        [[2.7104e-04]],\n",
       "\n",
       "        [[2.9693e-04]],\n",
       "\n",
       "        [[3.4671e-04]],\n",
       "\n",
       "        [[3.1465e-04]],\n",
       "\n",
       "        [[1.1507e-04]],\n",
       "\n",
       "        [[2.5428e-04]],\n",
       "\n",
       "        [[2.9876e-04]],\n",
       "\n",
       "        [[3.1614e-04]],\n",
       "\n",
       "        [[1.5914e-04]],\n",
       "\n",
       "        [[1.0949e-04]],\n",
       "\n",
       "        [[3.3419e-04]],\n",
       "\n",
       "        [[2.8547e-04]],\n",
       "\n",
       "        [[2.9799e-04]],\n",
       "\n",
       "        [[2.0596e-04]],\n",
       "\n",
       "        [[3.1286e-04]],\n",
       "\n",
       "        [[3.5396e-04]],\n",
       "\n",
       "        [[2.2458e-04]],\n",
       "\n",
       "        [[9.1964e-05]],\n",
       "\n",
       "        [[4.5097e-05]],\n",
       "\n",
       "        [[1.6480e-04]],\n",
       "\n",
       "        [[1.6132e-04]],\n",
       "\n",
       "        [[1.5180e-04]],\n",
       "\n",
       "        [[2.5887e-04]],\n",
       "\n",
       "        [[1.8588e-04]],\n",
       "\n",
       "        [[1.1208e-04]],\n",
       "\n",
       "        [[2.4590e-04]],\n",
       "\n",
       "        [[2.4481e-04]],\n",
       "\n",
       "        [[3.3715e-04]],\n",
       "\n",
       "        [[2.4364e-04]],\n",
       "\n",
       "        [[2.9804e-04]],\n",
       "\n",
       "        [[2.4933e-04]],\n",
       "\n",
       "        [[2.7982e-04]],\n",
       "\n",
       "        [[3.0472e-04]],\n",
       "\n",
       "        [[2.8638e-04]],\n",
       "\n",
       "        [[2.3667e-04]],\n",
       "\n",
       "        [[1.5964e-04]],\n",
       "\n",
       "        [[2.2699e-04]],\n",
       "\n",
       "        [[3.3432e-04]],\n",
       "\n",
       "        [[1.1735e-04]],\n",
       "\n",
       "        [[2.0138e-04]],\n",
       "\n",
       "        [[1.3726e-04]],\n",
       "\n",
       "        [[1.5344e-04]],\n",
       "\n",
       "        [[2.7559e-04]],\n",
       "\n",
       "        [[1.5775e-04]],\n",
       "\n",
       "        [[3.0523e-04]],\n",
       "\n",
       "        [[2.9573e-04]],\n",
       "\n",
       "        [[2.7232e-04]],\n",
       "\n",
       "        [[2.7350e-04]],\n",
       "\n",
       "        [[4.1519e-04]],\n",
       "\n",
       "        [[3.0074e-04]],\n",
       "\n",
       "        [[1.8282e-04]],\n",
       "\n",
       "        [[3.0792e-04]],\n",
       "\n",
       "        [[2.7813e-04]],\n",
       "\n",
       "        [[3.1668e-04]],\n",
       "\n",
       "        [[3.0468e-04]],\n",
       "\n",
       "        [[3.6079e-04]],\n",
       "\n",
       "        [[9.9973e-01]],\n",
       "\n",
       "        [[9.9982e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9972e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9975e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9989e-01]],\n",
       "\n",
       "        [[9.9983e-01]],\n",
       "\n",
       "        [[9.9986e-01]],\n",
       "\n",
       "        [[9.9969e-01]],\n",
       "\n",
       "        [[9.9972e-01]],\n",
       "\n",
       "        [[9.9972e-01]],\n",
       "\n",
       "        [[9.9971e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9982e-01]],\n",
       "\n",
       "        [[9.9975e-01]],\n",
       "\n",
       "        [[9.9978e-01]],\n",
       "\n",
       "        [[9.9980e-01]],\n",
       "\n",
       "        [[9.9989e-01]],\n",
       "\n",
       "        [[9.9980e-01]],\n",
       "\n",
       "        [[9.9985e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9988e-01]],\n",
       "\n",
       "        [[9.9970e-01]],\n",
       "\n",
       "        [[9.9974e-01]],\n",
       "\n",
       "        [[9.9986e-01]],\n",
       "\n",
       "        [[9.9988e-01]],\n",
       "\n",
       "        [[9.9968e-01]],\n",
       "\n",
       "        [[9.9972e-01]],\n",
       "\n",
       "        [[9.9982e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9978e-01]],\n",
       "\n",
       "        [[9.9986e-01]],\n",
       "\n",
       "        [[9.9962e-01]],\n",
       "\n",
       "        [[9.9981e-01]],\n",
       "\n",
       "        [[9.9980e-01]],\n",
       "\n",
       "        [[9.9983e-01]],\n",
       "\n",
       "        [[9.9978e-01]],\n",
       "\n",
       "        [[9.9968e-01]],\n",
       "\n",
       "        [[9.9973e-01]],\n",
       "\n",
       "        [[9.9973e-01]],\n",
       "\n",
       "        [[9.9980e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9974e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9981e-01]],\n",
       "\n",
       "        [[9.9967e-01]],\n",
       "\n",
       "        [[9.9963e-01]],\n",
       "\n",
       "        [[9.9984e-01]],\n",
       "\n",
       "        [[9.9969e-01]],\n",
       "\n",
       "        [[9.9984e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9972e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9970e-01]],\n",
       "\n",
       "        [[9.9981e-01]],\n",
       "\n",
       "        [[9.9989e-01]],\n",
       "\n",
       "        [[9.9986e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9972e-01]],\n",
       "\n",
       "        [[9.9979e-01]],\n",
       "\n",
       "        [[9.9972e-01]],\n",
       "\n",
       "        [[9.9966e-01]],\n",
       "\n",
       "        [[9.9987e-01]],\n",
       "\n",
       "        [[9.9985e-01]],\n",
       "\n",
       "        [[9.9974e-01]],\n",
       "\n",
       "        [[9.9970e-01]],\n",
       "\n",
       "        [[9.9998e-01]],\n",
       "\n",
       "        [[9.9990e-01]],\n",
       "\n",
       "        [[9.9986e-01]],\n",
       "\n",
       "        [[9.9975e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9981e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9993e-01]],\n",
       "\n",
       "        [[9.9966e-01]],\n",
       "\n",
       "        [[9.9969e-01]],\n",
       "\n",
       "        [[9.9983e-01]],\n",
       "\n",
       "        [[9.9979e-01]],\n",
       "\n",
       "        [[9.9965e-01]],\n",
       "\n",
       "        [[9.9981e-01]],\n",
       "\n",
       "        [[9.9979e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9981e-01]],\n",
       "\n",
       "        [[9.9989e-01]],\n",
       "\n",
       "        [[9.9987e-01]],\n",
       "\n",
       "        [[9.9985e-01]],\n",
       "\n",
       "        [[9.9975e-01]],\n",
       "\n",
       "        [[9.9974e-01]],\n",
       "\n",
       "        [[9.9982e-01]],\n",
       "\n",
       "        [[9.9975e-01]],\n",
       "\n",
       "        [[9.9980e-01]],\n",
       "\n",
       "        [[3.1186e-01]],\n",
       "\n",
       "        [[8.8890e-01]],\n",
       "\n",
       "        [[3.0583e-01]],\n",
       "\n",
       "        [[6.9242e-01]],\n",
       "\n",
       "        [[9.1649e-01]],\n",
       "\n",
       "        [[9.1833e-01]],\n",
       "\n",
       "        [[7.0626e-01]],\n",
       "\n",
       "        [[7.0215e-01]],\n",
       "\n",
       "        [[3.4805e-01]],\n",
       "\n",
       "        [[6.0788e-01]],\n",
       "\n",
       "        [[4.5475e-01]],\n",
       "\n",
       "        [[2.3791e-01]],\n",
       "\n",
       "        [[8.1575e-01]],\n",
       "\n",
       "        [[9.8586e-01]],\n",
       "\n",
       "        [[7.6398e-01]],\n",
       "\n",
       "        [[4.6387e-01]],\n",
       "\n",
       "        [[9.3649e-01]],\n",
       "\n",
       "        [[9.2520e-01]],\n",
       "\n",
       "        [[5.7549e-01]],\n",
       "\n",
       "        [[5.6810e-01]],\n",
       "\n",
       "        [[7.9145e-01]],\n",
       "\n",
       "        [[7.8863e-01]],\n",
       "\n",
       "        [[1.3556e-01]],\n",
       "\n",
       "        [[6.5018e-02]],\n",
       "\n",
       "        [[4.3066e-01]],\n",
       "\n",
       "        [[7.7736e-01]],\n",
       "\n",
       "        [[2.2718e-01]],\n",
       "\n",
       "        [[5.6854e-01]],\n",
       "\n",
       "        [[7.3444e-01]],\n",
       "\n",
       "        [[3.3351e-01]],\n",
       "\n",
       "        [[7.7830e-01]],\n",
       "\n",
       "        [[8.7239e-01]],\n",
       "\n",
       "        [[6.7198e-01]],\n",
       "\n",
       "        [[7.0907e-01]],\n",
       "\n",
       "        [[7.2266e-01]],\n",
       "\n",
       "        [[8.0752e-01]],\n",
       "\n",
       "        [[9.4033e-01]],\n",
       "\n",
       "        [[9.0044e-01]],\n",
       "\n",
       "        [[9.0041e-01]],\n",
       "\n",
       "        [[1.6266e-01]],\n",
       "\n",
       "        [[6.3589e-01]],\n",
       "\n",
       "        [[5.0702e-01]],\n",
       "\n",
       "        [[9.4411e-01]],\n",
       "\n",
       "        [[3.0186e-01]],\n",
       "\n",
       "        [[9.8266e-01]],\n",
       "\n",
       "        [[5.5774e-01]]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> 1b2a70f0654dff9b5cdc68dc78486fef0376fe06
    }
   ],
   "source": [
    "net(data_torch.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
