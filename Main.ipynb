{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and training Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.3.0\n",
      "syft version: 0.2.0a2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import syft as sy\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import time\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"syft version:\", sy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSamples(filename):\n",
    "    data = pd.read_csv(filename, sep='\\t')\n",
    "    return data.to_numpy()[:,1:].transpose()\n",
    "\n",
    "dim = 12634\n",
    "data1 = getSamples(\"GSE2034-Normal-train.txt\")\n",
    "data2 = getSamples(\"GSE2034-Tumor-train.txt\")\n",
    "\n",
    "data1Label = np.zeros(len(data1)).reshape((-1, 1))\n",
    "data2Label = np.ones(len(data2)).reshape((-1, 1))\n",
    "x = np.concatenate((data1, data2))\n",
    "y = np.concatenate((data1Label, data2Label))\n",
    "\n",
    "# shuffle the data\n",
    "idx = np.random.permutation(len(x))\n",
    "x,y = x[idx], y[idx]\n",
    "\n",
    "z = np.concatenate((x, y), axis = 1)\n",
    "\n",
    "# We follow an 80/20 partitioning for the training and testing sets\n",
    "n_train_items = 181\n",
    "n_test_items = 46\n",
    "\n",
    "# partition the data into training data and test data\n",
    "x_train = x[:n_train_items]\n",
    "y_train = y[:n_train_items]\n",
    "\n",
    "x_train = x_train.reshape((-1,1,dim))\n",
    "y_train = y_train.reshape((-1,1))\n",
    "\n",
    "x_test = x[n_train_items:]\n",
    "y_test = y[n_train_items:]    \n",
    "\n",
    "x_test = x_test.reshape((-1,1,dim))\n",
    "y_test = y_test.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting 80 20 for Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal = pd.read_csv(\"GSE2034-Normal-train.txt\", sep='\\t')\n",
    "\n",
    "df_train_normal = df_normal.iloc[:, 1:].sample(frac=0.8,random_state=200, axis=1)\n",
    "\n",
    "df_test_normal = df_normal.drop(df_train_normal.columns, axis=1)\n",
    "df_test_normal.to_csv(\"GSE2034-Normal_test.txt\", sep='\\t')\n",
    "\n",
    "df_train_normal = pd.concat((df_test_normal['Hybridization REF'], df_train_normal), axis=1)\n",
    "df_train_normal.to_csv(\"GSE2034-Normal_train.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tumor = pd.read_csv(\"GSE2034-Tumor-train.txt\", sep='\\t')\n",
    "\n",
    "df_train_tumor = df_tumor.iloc[:, 1:].sample(frac=0.8,random_state=200, axis=1)\n",
    "\n",
    "df_test_tumor = df_tumor.drop(df_train_tumor.columns, axis=1)\n",
    "df_test_tumor.to_csv(\"GSE2034-Tumor_test.txt\", sep='\\t')\n",
    "\n",
    "df_train_tumor = pd.concat((df_test_tumor['Hybridization REF'], df_train_tumor), axis=1)\n",
    "df_train_tumor.to_csv(\"GSE2034-Tumor_train.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GSE2034Dataset(Dataset):\n",
    "    \"\"\"GSE2034 dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, normal_csv_file, tumor_csv_file):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            normal_csv_file (string): Path to the csv file with normal.\n",
    "            tumor_csv_file (string): Path to the csv file with tumor.\n",
    "                \"\"\"\n",
    "        df_normal = pd.read_csv(normal_csv_file, sep='\\t')\n",
    "        df_normal.index = df_normal['Hybridization REF']\n",
    "        del df_normal['Hybridization REF']\n",
    "        df_normal = df_normal.T\n",
    "        df_normal['y'] = 0\n",
    "        \n",
    "        df_tumor = pd.read_csv(tumor_csv_file, sep='\\t')\n",
    "        df_tumor.index = df_tumor['Hybridization REF']\n",
    "        del df_tumor['Hybridization REF']\n",
    "        df_tumor = df_tumor.T\n",
    "        df_tumor['y'] = 1\n",
    "\n",
    "        self.df = pd.concat([df_normal, df_tumor])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return (torch.tensor(self.df.iloc[idx].iloc[:-1].values)\n",
    "                .float()\n",
    "                .unsqueeze(0), #add channel dimension\n",
    "                torch.tensor(self.df.iloc[idx].y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "trainset = GSE2034Dataset(\"GSE2034-Normal_train.txt\",\n",
    "                                    \"GSE2034-Tumor_train.txt\")\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "testset = GSE2034Dataset(\"GSE2034-Normal_test.txt\",\n",
    "                                    \"GSE2034-Tumor_test.txt\")\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/jestinepaul/miniconda3/envs/idash2019/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30..  Training Loss: 0.655..  Test Loss: 1.291.. \n",
      "Epoch: 2/30..  Training Loss: 0.531..  Test Loss: 1.236.. \n",
      "Epoch: 3/30..  Training Loss: 0.363..  Test Loss: 1.117.. \n",
      "Epoch: 4/30..  Training Loss: 0.259..  Test Loss: 1.006.. \n",
      "Epoch: 5/30..  Training Loss: 0.194..  Test Loss: 1.133.. \n",
      "Epoch: 6/30..  Training Loss: 0.170..  Test Loss: 1.004.. \n",
      "Epoch: 7/30..  Training Loss: 0.150..  Test Loss: 1.100.. \n",
      "Epoch: 8/30..  Training Loss: 0.144..  Test Loss: 1.075.. \n",
      "Epoch: 9/30..  Training Loss: 0.142..  Test Loss: 1.136.. \n",
      "Epoch: 10/30..  Training Loss: 0.141..  Test Loss: 1.742.. \n",
      "Epoch: 11/30..  Training Loss: 0.140..  Test Loss: 1.061.. \n",
      "Epoch: 12/30..  Training Loss: 0.140..  Test Loss: 1.120.. \n",
      "Epoch: 13/30..  Training Loss: 0.140..  Test Loss: 1.730.. \n",
      "Epoch: 14/30..  Training Loss: 0.140..  Test Loss: 1.121.. \n",
      "Epoch: 15/30..  Training Loss: 0.139..  Test Loss: 1.063.. \n",
      "Epoch: 16/30..  Training Loss: 0.139..  Test Loss: 1.143.. \n",
      "Epoch: 17/30..  Training Loss: 0.139..  Test Loss: 1.033.. \n",
      "Epoch: 18/30..  Training Loss: 0.139..  Test Loss: 1.079.. \n",
      "Epoch: 19/30..  Training Loss: 0.139..  Test Loss: 1.079.. \n",
      "Epoch: 20/30..  Training Loss: 0.139..  Test Loss: 1.090.. \n",
      "Epoch: 21/30..  Training Loss: 0.139..  Test Loss: 1.989.. \n",
      "Epoch: 22/30..  Training Loss: 0.139..  Test Loss: 1.134.. \n",
      "Epoch: 23/30..  Training Loss: 0.139..  Test Loss: 1.841.. \n",
      "Epoch: 24/30..  Training Loss: 0.139..  Test Loss: 1.062.. \n",
      "Epoch: 25/30..  Training Loss: 0.139..  Test Loss: 1.708.. \n",
      "Epoch: 26/30..  Training Loss: 0.139..  Test Loss: 1.196.. \n",
      "Epoch: 27/30..  Training Loss: 0.139..  Test Loss: 1.128.. \n",
      "Epoch: 28/30..  Training Loss: 0.139..  Test Loss: 1.150.. \n",
      "Epoch: 29/30..  Training Loss: 0.139..  Test Loss: 1.833.. \n",
      "Epoch: 30/30..  Training Loss: 0.139..  Test Loss: 1.208.. \n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for genes, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(genes.cuda())\n",
    "        loss = criterion(output, labels.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            for genes, labels in testloader:\n",
    "                output = model(genes.cuda())\n",
    "                test_loss += criterion(output, labels.cuda())\n",
    "                \n",
    "#                 ps = torch.exp(log_ps)\n",
    "#                 top_p, top_class = ps.topk(1, dim=1)\n",
    "#                 equals = top_class == labels.view(*top_class.shape)\n",
    "#                 accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "#               \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader))\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gse2034dataset = GSE2034Dataset(\"GSE2034-Normal-train.txt\",\n",
    "                                    \"GSE2034-Tumor-train.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gse2034dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(gse2034dataset, batch_size=30,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, (x,y) in enumerate(dataloader):\n",
    "    print(i_batch, x.to(device), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, (x,y) in enumerate(dataloader):\n",
    "#     print(i_batch, sample_batched)    \n",
    "    # zero the parameter gradients  \n",
    "    optimizer.zero_grad()\n",
    "    print(x.shape)\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(x.cuda())\n",
    "    loss = criterion(outputs, y.cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(i_batch, \"% Trained\", \"loss = \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data into (batch, channel = 1, length=dim)\n",
    "data_torch = torch.from_numpy(x).view([-1, 1, dim]).float()\n",
    "label_torch = torch.from_numpy(y).view([-1,1,1]).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Model applied to GSE2034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 12634\n",
    "\n",
    "class Res1d(nn.Module):\n",
    "    # the conv layers\n",
    "    def __init__(self, inSize, outSize, kernel=(3,), strides=1,):\n",
    "        super(Res1d, self).__init__()\n",
    "        \n",
    "        # Left , kernel size 3\n",
    "        # hard-coded to do the padding correctly\n",
    "        if inSize in (16,64,128,512) and strides > 1:\n",
    "            pding = 0\n",
    "        else:\n",
    "            pding = 1\n",
    "            \n",
    "        self.l = nn.Sequential(\n",
    "            nn.Conv1d(inSize, outSize, kernel, stride=strides, padding=pding, bias=False),\n",
    "            nn.InstanceNorm1d(outSize)\n",
    "        )    \n",
    "        \n",
    "        # Right, kernel size 1\n",
    "        if inSize != outSize or strides > 1:\n",
    "            if strides > 1:\n",
    "                self.r1 = nn.AvgPool1d(strides)\n",
    "            else:\n",
    "                self.r1 = nn.Identity()\n",
    "                \n",
    "        self.r = nn.Sequential(\n",
    "            self.r1,\n",
    "            nn.Conv1d(inSize, outSize, 1, bias=False),\n",
    "            nn.InstanceNorm1d(outSize)\n",
    "        )\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):          \n",
    "        x = self.l(x) + self.r(x)\n",
    "        return self.relu(x)\n",
    "    \n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.l = nn.Sequential(\n",
    "            nn.Linear(dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self.r = nn.Sequential(\n",
    "            Res1d(1, 4, 3),\n",
    "\n",
    "            Res1d(4, 8, 3),\n",
    "            Res1d(8, 8, 3, strides=2),\n",
    "\n",
    "            Res1d(8, 16, 3),\n",
    "            Res1d(16, 16, 3, strides=2),\n",
    "\n",
    "            Res1d(16, 32, 3),\n",
    "            Res1d(32, 32, 3, strides=2),\n",
    "\n",
    "            Res1d(32, 64, 3),\n",
    "            Res1d(64, 64, 3, strides=2),\n",
    "\n",
    "            Res1d(64, 128, 3),\n",
    "            Res1d(128, 128, 3, strides=2),\n",
    "\n",
    "            Res1d(128, 256, 3),\n",
    "            Res1d(256, 256, 3, strides=2),\n",
    "\n",
    "            Res1d(256, 512, 3),\n",
    "            Res1d(512, 512, 3, strides=2),\n",
    "\n",
    "            Res1d(512, 1024, 3),\n",
    "            Res1d(1024, 1024, 3, strides=2),\n",
    "\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # size is by experiment and hardcode\n",
    "        self.last = nn.Sequential(\n",
    "            nn.Linear(50240,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # shape is (batch, channel, time)\n",
    "        l = self.l(x)\n",
    "#         l.squeeze_(-2)\n",
    "        r = self.r(x)\n",
    "#         r.unsqueeze_(-2) # add channel dimension\n",
    "        y = torch.cat((l,r),dim=-1)\n",
    "        y = self.last(y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 64]         808,640\n",
      "              ReLU-2                [-1, 1, 64]               0\n",
      "           Flatten-3                   [-1, 64]               0\n",
      "            Conv1d-4             [-1, 4, 12634]              12\n",
      "    InstanceNorm1d-5             [-1, 4, 12634]               0\n",
      "          Identity-6             [-1, 1, 12634]               0\n",
      "          Identity-7             [-1, 1, 12634]               0\n",
      "            Conv1d-8             [-1, 4, 12634]               4\n",
      "    InstanceNorm1d-9             [-1, 4, 12634]               0\n",
      "             ReLU-10             [-1, 4, 12634]               0\n",
      "            Res1d-11             [-1, 4, 12634]               0\n",
      "           Conv1d-12             [-1, 8, 12634]              96\n",
      "   InstanceNorm1d-13             [-1, 8, 12634]               0\n",
      "         Identity-14             [-1, 4, 12634]               0\n",
      "         Identity-15             [-1, 4, 12634]               0\n",
      "           Conv1d-16             [-1, 8, 12634]              32\n",
      "   InstanceNorm1d-17             [-1, 8, 12634]               0\n",
      "             ReLU-18             [-1, 8, 12634]               0\n",
      "            Res1d-19             [-1, 8, 12634]               0\n",
      "           Conv1d-20              [-1, 8, 6317]             192\n",
      "   InstanceNorm1d-21              [-1, 8, 6317]               0\n",
      "        AvgPool1d-22              [-1, 8, 6317]               0\n",
      "        AvgPool1d-23              [-1, 8, 6317]               0\n",
      "           Conv1d-24              [-1, 8, 6317]              64\n",
      "   InstanceNorm1d-25              [-1, 8, 6317]               0\n",
      "             ReLU-26              [-1, 8, 6317]               0\n",
      "            Res1d-27              [-1, 8, 6317]               0\n",
      "           Conv1d-28             [-1, 16, 6317]             384\n",
      "   InstanceNorm1d-29             [-1, 16, 6317]               0\n",
      "         Identity-30              [-1, 8, 6317]               0\n",
      "         Identity-31              [-1, 8, 6317]               0\n",
      "           Conv1d-32             [-1, 16, 6317]             128\n",
      "   InstanceNorm1d-33             [-1, 16, 6317]               0\n",
      "             ReLU-34             [-1, 16, 6317]               0\n",
      "            Res1d-35             [-1, 16, 6317]               0\n",
      "           Conv1d-36             [-1, 16, 3158]             768\n",
      "   InstanceNorm1d-37             [-1, 16, 3158]               0\n",
      "        AvgPool1d-38             [-1, 16, 3158]               0\n",
      "        AvgPool1d-39             [-1, 16, 3158]               0\n",
      "           Conv1d-40             [-1, 16, 3158]             256\n",
      "   InstanceNorm1d-41             [-1, 16, 3158]               0\n",
      "             ReLU-42             [-1, 16, 3158]               0\n",
      "            Res1d-43             [-1, 16, 3158]               0\n",
      "           Conv1d-44             [-1, 32, 3158]           1,536\n",
      "   InstanceNorm1d-45             [-1, 32, 3158]               0\n",
      "         Identity-46             [-1, 16, 3158]               0\n",
      "         Identity-47             [-1, 16, 3158]               0\n",
      "           Conv1d-48             [-1, 32, 3158]             512\n",
      "   InstanceNorm1d-49             [-1, 32, 3158]               0\n",
      "             ReLU-50             [-1, 32, 3158]               0\n",
      "            Res1d-51             [-1, 32, 3158]               0\n",
      "           Conv1d-52             [-1, 32, 1579]           3,072\n",
      "   InstanceNorm1d-53             [-1, 32, 1579]               0\n",
      "        AvgPool1d-54             [-1, 32, 1579]               0\n",
      "        AvgPool1d-55             [-1, 32, 1579]               0\n",
      "           Conv1d-56             [-1, 32, 1579]           1,024\n",
      "   InstanceNorm1d-57             [-1, 32, 1579]               0\n",
      "             ReLU-58             [-1, 32, 1579]               0\n",
      "            Res1d-59             [-1, 32, 1579]               0\n",
      "           Conv1d-60             [-1, 64, 1579]           6,144\n",
      "   InstanceNorm1d-61             [-1, 64, 1579]               0\n",
      "         Identity-62             [-1, 32, 1579]               0\n",
      "         Identity-63             [-1, 32, 1579]               0\n",
      "           Conv1d-64             [-1, 64, 1579]           2,048\n",
      "   InstanceNorm1d-65             [-1, 64, 1579]               0\n",
      "             ReLU-66             [-1, 64, 1579]               0\n",
      "            Res1d-67             [-1, 64, 1579]               0\n",
      "           Conv1d-68              [-1, 64, 789]          12,288\n",
      "   InstanceNorm1d-69              [-1, 64, 789]               0\n",
      "        AvgPool1d-70              [-1, 64, 789]               0\n",
      "        AvgPool1d-71              [-1, 64, 789]               0\n",
      "           Conv1d-72              [-1, 64, 789]           4,096\n",
      "   InstanceNorm1d-73              [-1, 64, 789]               0\n",
      "             ReLU-74              [-1, 64, 789]               0\n",
      "            Res1d-75              [-1, 64, 789]               0\n",
      "           Conv1d-76             [-1, 128, 789]          24,576\n",
      "   InstanceNorm1d-77             [-1, 128, 789]               0\n",
      "         Identity-78              [-1, 64, 789]               0\n",
      "         Identity-79              [-1, 64, 789]               0\n",
      "           Conv1d-80             [-1, 128, 789]           8,192\n",
      "   InstanceNorm1d-81             [-1, 128, 789]               0\n",
      "             ReLU-82             [-1, 128, 789]               0\n",
      "            Res1d-83             [-1, 128, 789]               0\n",
      "           Conv1d-84             [-1, 128, 394]          49,152\n",
      "   InstanceNorm1d-85             [-1, 128, 394]               0\n",
      "        AvgPool1d-86             [-1, 128, 394]               0\n",
      "        AvgPool1d-87             [-1, 128, 394]               0\n",
      "           Conv1d-88             [-1, 128, 394]          16,384\n",
      "   InstanceNorm1d-89             [-1, 128, 394]               0\n",
      "             ReLU-90             [-1, 128, 394]               0\n",
      "            Res1d-91             [-1, 128, 394]               0\n",
      "           Conv1d-92             [-1, 256, 394]          98,304\n",
      "   InstanceNorm1d-93             [-1, 256, 394]               0\n",
      "         Identity-94             [-1, 128, 394]               0\n",
      "         Identity-95             [-1, 128, 394]               0\n",
      "           Conv1d-96             [-1, 256, 394]          32,768\n",
      "   InstanceNorm1d-97             [-1, 256, 394]               0\n",
      "             ReLU-98             [-1, 256, 394]               0\n",
      "            Res1d-99             [-1, 256, 394]               0\n",
      "          Conv1d-100             [-1, 256, 197]         196,608\n",
      "  InstanceNorm1d-101             [-1, 256, 197]               0\n",
      "       AvgPool1d-102             [-1, 256, 197]               0\n",
      "       AvgPool1d-103             [-1, 256, 197]               0\n",
      "          Conv1d-104             [-1, 256, 197]          65,536\n",
      "  InstanceNorm1d-105             [-1, 256, 197]               0\n",
      "            ReLU-106             [-1, 256, 197]               0\n",
      "           Res1d-107             [-1, 256, 197]               0\n",
      "          Conv1d-108             [-1, 512, 197]         393,216\n",
      "  InstanceNorm1d-109             [-1, 512, 197]               0\n",
      "        Identity-110             [-1, 256, 197]               0\n",
      "        Identity-111             [-1, 256, 197]               0\n",
      "          Conv1d-112             [-1, 512, 197]         131,072\n",
      "  InstanceNorm1d-113             [-1, 512, 197]               0\n",
      "            ReLU-114             [-1, 512, 197]               0\n",
      "           Res1d-115             [-1, 512, 197]               0\n",
      "          Conv1d-116              [-1, 512, 98]         786,432\n",
      "  InstanceNorm1d-117              [-1, 512, 98]               0\n",
      "       AvgPool1d-118              [-1, 512, 98]               0\n",
      "       AvgPool1d-119              [-1, 512, 98]               0\n",
      "          Conv1d-120              [-1, 512, 98]         262,144\n",
      "  InstanceNorm1d-121              [-1, 512, 98]               0\n",
      "            ReLU-122              [-1, 512, 98]               0\n",
      "           Res1d-123              [-1, 512, 98]               0\n",
      "          Conv1d-124             [-1, 1024, 98]       1,572,864\n",
      "  InstanceNorm1d-125             [-1, 1024, 98]               0\n",
      "        Identity-126              [-1, 512, 98]               0\n",
      "        Identity-127              [-1, 512, 98]               0\n",
      "          Conv1d-128             [-1, 1024, 98]         524,288\n",
      "  InstanceNorm1d-129             [-1, 1024, 98]               0\n",
      "            ReLU-130             [-1, 1024, 98]               0\n",
      "           Res1d-131             [-1, 1024, 98]               0\n",
      "          Conv1d-132             [-1, 1024, 49]       3,145,728\n",
      "  InstanceNorm1d-133             [-1, 1024, 49]               0\n",
      "       AvgPool1d-134             [-1, 1024, 49]               0\n",
      "       AvgPool1d-135             [-1, 1024, 49]               0\n",
      "          Conv1d-136             [-1, 1024, 49]       1,048,576\n",
      "  InstanceNorm1d-137             [-1, 1024, 49]               0\n",
      "            ReLU-138             [-1, 1024, 49]               0\n",
      "           Res1d-139             [-1, 1024, 49]               0\n",
      "         Flatten-140                [-1, 50176]               0\n",
      "          Linear-141                   [-1, 32]       1,607,712\n",
      "            ReLU-142                   [-1, 32]               0\n",
      "          Linear-143                    [-1, 1]              33\n",
      "         Sigmoid-144                    [-1, 1]               0\n",
      "         Flatten-145                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 10,804,881\n",
      "Trainable params: 10,804,881\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 70.62\n",
      "Params size (MB): 41.22\n",
      "Estimated Total Size (MB): 111.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = Model().to(device)\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(model,(1,12634))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on plain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = torch.from_numpy(x_test).view([-1, 1, dim]).float().cuda()\n",
    "test_labels = torch.from_numpy(y_test).view([-1, 1]).float().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = torch.from_numpy(x_test).view([-1, 1, dim]).float().cuda()\n",
    "test_labels = torch.from_numpy(y_test).view([-1, 1]).float().cuda()\n",
    "for batch in range(100):  # loop over the dataset multiple times\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    indices = np.random.choice(len(x_train), size=(30))\n",
    "    inputs = x_train[indices]\n",
    "    labels = y_train[indices]\n",
    "    \n",
    "    inputs = torch.from_numpy(inputs).float().cuda()\n",
    "    labels = torch.from_numpy(labels).float().cuda()\n",
    "    \n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs).view([-1,1]).cuda()\n",
    "    loss = criterion(outputs, labels).cuda()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(batch, \"% Trained\", \"loss = \", loss.item())\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = data_torch.cuda()\n",
    "net(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup of the secure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "def connect_to_workers(n_workers):\n",
    "    return [\n",
    "        sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n",
    "        for i in range(n_workers)\n",
    "    ]\n",
    "\n",
    "def connect_to_crypto_provider():\n",
    "    return sy.VirtualWorker(hook, id=\"crypto_provider\")\n",
    "\n",
    "workers = connect_to_workers(n_workers=2)\n",
    "crypto_provider = connect_to_crypto_provider()\n",
    "\n",
    "def get_private_data_loaders(precision_fractional, workers, crypto_provider):\n",
    "    \n",
    "    def secret_share(tensor): #Transforms to fixed precision and secret share a tensor\n",
    "        return (\n",
    "            tensor\n",
    "            .fix_precision(precision_fractional=precision_fractional)\n",
    "            .share(*workers, crypto_provider=crypto_provider, requires_grad=True)\n",
    "        )\n",
    "    \n",
    "    private_train_loader = [\n",
    "        (secret_share(torch.Tensor(x_train[i*5:i*5+5])), secret_share(torch.Tensor(y_train[i*5:i*5+5])))\n",
    "        for i in range (n_train_items)\n",
    "        if i < n_train_items / 5\n",
    "    ]\n",
    "    \n",
    "    private_test_loader = [\n",
    "        (secret_share(torch.Tensor(x_test[i*5:i*5+5])), secret_share(torch.Tensor(y_test[i*5:i*5+5])))\n",
    "        for i in range (n_train_items)\n",
    "        if i < n_train_items / 5\n",
    "    ]\n",
    "    return private_train_loader, private_test_loader\n",
    "    \n",
    "    \n",
    "private_train_loader, private_test_loader = get_private_data_loaders(\n",
    "    precision_fractional=3,\n",
    "    workers=workers,\n",
    "    crypto_provider=crypto_provider\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for encrypted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res1d(nn.Module):\n",
    "    # the conv layers\n",
    "    def __init__(self, inSize, outSize, kernel=(3,), strides=1,):\n",
    "        super(Res1d, self).__init__()\n",
    "        self.inSize = inSize\n",
    "        self.outSize = outSize\n",
    "        # hard-coded to do the padding correctly\n",
    "        if inSize in (16,64,128,512) and strides is 2:\n",
    "            pding = 0\n",
    "        else:\n",
    "            pding = 1\n",
    "        self.l1 = nn.Conv1d(inSize, outSize, kernel, stride=strides, padding=pding, bias=False)\n",
    "        self.l2 = nn.Identity()\n",
    "        \n",
    "        if strides > 1 or inSize != outSize:\n",
    "            if strides > 1:\n",
    "                self.r1 = nn.Identity()\n",
    "                self.r2 = nn.AvgPool1d(strides)\n",
    "            else:\n",
    "                self.r1 = None\n",
    "                self.r2 = None\n",
    "            self.r3 = nn.Conv1d(inSize, outSize, 1, bias=False)\n",
    "            self.r4 = nn.Identity()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        l = x\n",
    "        l = self.l1(l)\n",
    "        l = self.l2(l)\n",
    "        \n",
    "        if self.r1 is not None:\n",
    "            r = self.r1(x)\n",
    "            r = self.r2(r)\n",
    "            r = self.r3(r)\n",
    "            r = self.r4(r)\n",
    "        else:\n",
    "            r = self.r3(x)\n",
    "            r = self.r4(r)\n",
    "            \n",
    "        x = l + r\n",
    "        print(\"forwarding: \", self.inSize, self.outSize)\n",
    "        return F.relu(x)\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(dim, 64)\n",
    "        self.l2 = F.relu\n",
    "        \n",
    "        self.r1 = Res1d(1, 4, 3)\n",
    "        \n",
    "        self.r2 = Res1d(4, 8, 3)\n",
    "        self.r3 = Res1d(8, 8, 3, strides=2)\n",
    "        \n",
    "        self.r4 = Res1d(8, 16, 3)\n",
    "        self.r5 = Res1d(16, 16, 3, strides=2)\n",
    "        \n",
    "        self.r6 = Res1d(16, 32, 3)\n",
    "        self.r7 = Res1d(32, 32, 3, strides=2)\n",
    "        \n",
    "        self.r8 = Res1d(32, 64, 3)\n",
    "        self.r9 = Res1d(64, 64, 3, strides=2)\n",
    "        \n",
    "        self.r10 = Res1d(64, 128, 3)\n",
    "        self.r11 = Res1d(128, 128, 3, strides=2)\n",
    "        \n",
    "        self.r12 = Res1d(128, 256, 3)\n",
    "        self.r13 = Res1d(256, 256, 3, strides=2)\n",
    "        \n",
    "        self.r14 = Res1d(256, 512, 3)\n",
    "        self.r15 = Res1d(512, 512, 3, strides=2)\n",
    "        \n",
    "        self.r16 = Res1d(512, 1024, 3)\n",
    "        self.r17 = Res1d(1024, 1024, 3, strides=2)\n",
    "        \n",
    "        # size is by experiment and hardcode\n",
    "        self.lastLinear = nn.Linear(50240,32)\n",
    "        self.lastRelu = F.relu\n",
    "        self.lastAgg = nn.Linear(32,1)\n",
    "        self.lastSigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):           \n",
    "        # shape is (batch, channel, time)\n",
    "        l = x\n",
    "        l = x.view(x.shape[0],-1)\n",
    "        l = self.l1(l)\n",
    "        l = self.l2(l)\n",
    "\n",
    "        # conv layers should operate on time\n",
    "        r = x\n",
    "        r = self.r1(r)\n",
    "        r = self.r4(self.r3(self.r2(r)))\n",
    "        r = self.r8(self.r7(self.r6(self.r5(r))))\n",
    "        r = self.r12(self.r11(self.r10(self.r9(r))))\n",
    "        r = self.r16(self.r15(self.r14(self.r13(r))))\n",
    "        r = self.r17(r)\n",
    "        \n",
    "        # flatten l\n",
    "        r = r.view(x.shape[0],-1)\n",
    "        l = l.view(x.shape[0],-1)\n",
    "        y = torch.cat((l,r),dim=1)\n",
    "        y = self.lastLinear(y)\n",
    "        y = self.lastRelu(y)\n",
    "        y = self.lastAgg(y)\n",
    "        y = self.lastSigmoid(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, private_train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(private_train_loader): # <-- now it is a private dataset\n",
    "        print('training...')\n",
    "        start_time = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        batch_size = output.shape[0]\n",
    "        loss = ((output - target)**2).sum().refresh()/batch_size\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "#Although the aim of this project was to provide private training, we prepared code for testing as well\n",
    "def test(model, private_test_loader):\n",
    "    print('testing...')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in private_test_loader:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target.view_as(pred)).sum()\n",
    "\n",
    "    correct = correct.get().float_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model = model.fix_precision().share(*workers, crypto_provider=crypto_provider, requires_grad=True)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "optimizer = optimizer.fix_precision() \n",
    "for epoch in range(1, 2):\n",
    "    train(model, private_train_loader, optimizer, epoch)\n",
    "    test(model, private_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
