{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import torch; print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torchvision import transforms\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 14\n",
    "        self.test_batch_size = 14\n",
    "        self.epochs = 10\n",
    "        self.lr = 0.02\n",
    "        self.seed = 1\n",
    "        self.log_interval = 1 # Log info at each batch\n",
    "        self.precision_fractional = 3\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "_ = torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/souhail/.local/lib/python3.7/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_2.0.0.so'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/souhail/.local/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "def connect_to_workers(n_workers):\n",
    "    return [\n",
    "        sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n",
    "        for i in range(n_workers)\n",
    "    ]\n",
    "def connect_to_crypto_provider():\n",
    "    return sy.VirtualWorker(hook, id=\"crypto_provider\")\n",
    "\n",
    "workers = connect_to_workers(n_workers=2)\n",
    "crypto_provider = connect_to_crypto_provider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def getSamples(filename):\n",
    "    data = pd.read_csv(filename, sep='\\t')\n",
    "    return data.values[:,1:].transpose()\n",
    "\n",
    "data1 = getSamples(\"GSE2034-Normal-train.txt\")\n",
    "data2 = getSamples(\"GSE2034-Tumor-train.txt\")\n",
    "\n",
    "data1Label = np.zeros(len(data1)).reshape((-1, 1))\n",
    "data2Label = np.ones(len(data2)).reshape((-1, 1))\n",
    "x = np.concatenate((data1, data2))\n",
    "y = np.concatenate((data1Label, data2Label))\n",
    "z = np.concatenate((x, y), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't use the whole dataset for efficiency purpose, but feel free to increase these numbers\n",
    "n_train_items = 181\n",
    "n_test_items = 46\n",
    "\n",
    "# partition the data into training data and test data\n",
    "x_train = x[:n_train_items]\n",
    "y_train = y[:n_train_items]\n",
    "z_train = z[:n_train_items]\n",
    "\n",
    "x_test = x[n_train_items:]\n",
    "y_test = y[n_train_items:]    \n",
    "z_test = z[n_train_items:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 12635)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_private_data_loaders(precision_fractional, workers, crypto_provider):\n",
    "    \n",
    "    def one_hot_of(index_tensor):#Transforms to one hot tensor\n",
    "     \n",
    "        onehot_tensor = torch.zeros(*index_tensor.shape, 2) # 2 Output classes\n",
    "        onehot_tensor = onehot_tensor.scatter(1, index_tensor.view(-1, 1), 1)\n",
    "        return onehot_tensor\n",
    "        \n",
    "    def secret_share(tensor): #Transforms to fixed precision and secret share a tensor\n",
    "\n",
    "        return (\n",
    "            tensor\n",
    "            .fix_precision(precision_fractional=precision_fractional)\n",
    "            .share(*workers, crypto_provider=crypto_provider, requires_grad=True)\n",
    "        )\n",
    "    \n",
    "    transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        x_train,\n",
    "        batch_size=args.batch_size\n",
    "    )\n",
    "\n",
    "    private_train_loader = [\n",
    "        (secret_share(torch.from_numpy(x_train)), secret_share(torch.from_numpy(y_train)))\n",
    "        for i in range (n_train_items)\n",
    "    ]\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        z_test,\n",
    "        batch_size=args.test_batch_size\n",
    "    )\n",
    "        \n",
    "    private_test_loader = [\n",
    "        (secret_share(torch.from_numpy(x_test)), secret_share(torch.from_numpy(y_test)))\n",
    "        for i in range (n_test_items)\n",
    "    ]\n",
    "    return private_train_loader, private_test_loader\n",
    "    \n",
    "    \n",
    "private_train_loader, private_test_loader = get_private_data_loaders(\n",
    "    precision_fractional=args.precision_fractional,\n",
    "    workers=workers,\n",
    "    crypto_provider=crypto_provider\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 12634\n",
    "\n",
    "class Res1d(nn.Module):\n",
    "    # the conv layers\n",
    "    def __init__(self, inSize, outSize, kernel=(3,), strides=1,):\n",
    "        super(Res1d, self).__init__()\n",
    "        # hard-coded to do the padding correctly\n",
    "        if inSize in (16,64,128,512) and strides is 2:\n",
    "            pding = 0\n",
    "        else:\n",
    "            pding = 1\n",
    "        self.l1 = nn.Conv1d(inSize, outSize, kernel, stride=strides, padding=pding, bias=False)\n",
    "        self.l2 = nn.InstanceNorm1d(outSize)\n",
    "        \n",
    "        if strides > 1 or inSize != outSize:\n",
    "            if strides > 1:\n",
    "                self.r1 = nn.Identity()\n",
    "                self.r2 = nn.AvgPool1d(strides)\n",
    "            else:\n",
    "                self.r1 = None\n",
    "                self.r2 = None\n",
    "            self.r3 = nn.Conv1d(inSize, outSize, 1, bias=False)\n",
    "            self.r4 = nn.InstanceNorm1d(outSize)\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        l = self.l1(x)\n",
    "        l = self.l2(l)\n",
    "        \n",
    "        if self.r1 is not None:\n",
    "            r = self.r1(x)\n",
    "            r = self.r2(r)\n",
    "            r = self.r3(r)\n",
    "            r = self.r4(r)\n",
    "        else:\n",
    "            r = self.r3(x)\n",
    "            r = self.r4(r)\n",
    "            \n",
    "        x = l + r\n",
    "        return self.relu(x)\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(dim, 64)\n",
    "        self.l2 = nn.ReLU()\n",
    "        \n",
    "        self.r1 = Res1d(1, 4, 3)\n",
    "        \n",
    "        self.r2 = Res1d(4, 8, 3)\n",
    "        self.r3 = Res1d(8, 8, 3, strides=2)\n",
    "        \n",
    "        self.r4 = Res1d(8, 16, 3)\n",
    "        self.r5 = Res1d(16, 16, 3, strides=2)\n",
    "        \n",
    "        self.r6 = Res1d(16, 32, 3)\n",
    "        self.r7 = Res1d(32, 32, 3, strides=2)\n",
    "        \n",
    "        self.r8 = Res1d(32, 64, 3)\n",
    "        self.r9 = Res1d(64, 64, 3, strides=2)\n",
    "        \n",
    "        self.r10 = Res1d(64, 128, 3)\n",
    "        self.r11 = Res1d(128, 128, 3, strides=2)\n",
    "        \n",
    "        self.r12 = Res1d(128, 256, 3)\n",
    "        self.r13 = Res1d(256, 256, 3, strides=2)\n",
    "        \n",
    "        self.r14 = Res1d(256, 512, 3)\n",
    "        self.r15 = Res1d(512, 512, 3, strides=2)\n",
    "        \n",
    "        self.r16 = Res1d(512, 1024, 3)\n",
    "        self.r17 = Res1d(1024, 1024, 3, strides=2)\n",
    "        \n",
    "        # size is by experiment and hardcode\n",
    "        self.lastLinear = nn.Linear(50240,32)\n",
    "        self.lastRelu = nn.ReLU()\n",
    "        self.lastAgg = nn.Linear(32,1)\n",
    "        self.lastSigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # shape is (batch, channel, time)\n",
    "        l = x\n",
    "        l = self.l2(self.l1(l))\n",
    "        \n",
    "        # conv layers should operate on time\n",
    "        r = x\n",
    "        r = self.r4(self.r3(self.r2(self.r1(r))))\n",
    "        r = self.r8(self.r7(self.r6(self.r5(r))))\n",
    "        r = self.r12(self.r11(self.r10(self.r9(r))))\n",
    "        r = self.r16(self.r15(self.r14(self.r13(r))))\n",
    "        r = self.r17(r)\n",
    "        \n",
    "        # flatten l\n",
    "        r = r.view(x.shape[0],1, -1)\n",
    "        y = torch.cat((l,r),-1)\n",
    "        y = self.lastLinear(y)\n",
    "        y = self.lastRelu(y)\n",
    "        y = self.lastAgg(y)\n",
    "        y = self.lastSigmoid(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, private_train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(private_train_loader): # <-- now it is a private dataset\n",
    "        start_time = time.time()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        # loss = F.nll_loss(output, target)  <-- not possible here\n",
    "        batch_size = output.shape[0]\n",
    "        loss = ((output - target)**2).sum().refresh()/batch_size\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get().float_precision()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime: {:.3f}s'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(private_train_loader) * args.batch_size,\n",
    "                100. * batch_idx / len(private_train_loader), loss.item(), time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, private_test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in private_test_loader:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target.view_as(pred)).sum()\n",
    "\n",
    "    correct = correct.get().float_precision()\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct.item(), len(private_test_loader)* args.test_batch_size,\n",
    "        100. * correct.item() / (len(private_test_loader) * args.test_batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__bool__ should return bool, returned Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e79443039c9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivate_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivate_test_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9a389bf26923>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, private_train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# loss = F.nll_loss(output, target)  <-- not possible here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-3527a23acd44>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# shape is (batch, channel, time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# conv layers should operate on time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/generic/frameworks/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0mhandle_func_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mnew_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_command\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;31m# Put back the wrappers where needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/autograd.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;31m# Try to get recursively the attributes in cmd = \"<attr1>.<attr2>.<attr3>...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/autograd.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    200\u001b[0m                     \u001b[0mUn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhook\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mto\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mits\u001b[0m \u001b[0mdetailed\u001b[0m \u001b[0mbehaviour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \"\"\"\n\u001b[0;32m--> 202\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnative_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/generic/frameworks/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0mhandle_func_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/autograd.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;31m# Try to get recursively the attributes in cmd = \"<attr1>.<attr2>.<attr3>...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/autograd.py\u001b[0m in \u001b[0;36maddmm\u001b[0;34m(bias, input_tensor, weight)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mmatmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/autograd.py\u001b[0m in \u001b[0;36mmethod_with_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 )\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;31m# Put back SyftTensor on the tensors found in the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/precision.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matmul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;31m# Put back SyftTensor on the tensors found in the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_public_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matmul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_private_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matmul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36m_private_mul\u001b[0;34m(self, other, equation)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"For multiplication a crypto_provider must be passed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mshares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspdz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspdz_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrypto_provider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mshares\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/frameworks/torch/crypto/spdz.py\u001b[0m in \u001b[0;36mspdz_mul\u001b[0;34m(cmd, x_sh, y_sh, crypto_provider, field)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_sh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Reconstruct and send to all workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36mreconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mptr_to_sh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mno_wrap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mptr_to_sh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, inplace, local_autograd, preinitialize_grad, no_wrap, garbage_collect_data, *location)\u001b[0m\n\u001b[1;32m    377\u001b[0m                 \u001b[0mlocal_autograd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_autograd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0mpreinitialize_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreinitialize_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0mgarbage_collect_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgarbage_collect_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             )\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/workers/base.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj, workers, ptr_id, garbage_collect_data, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# Send the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/workers/base.py\u001b[0m in \u001b[0;36msend_obj\u001b[0;34m(self, obj, location)\u001b[0m\n\u001b[1;32m    567\u001b[0m                 \u001b[0mreceive\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \"\"\"\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mObjectMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"BaseWorker\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;31m# Step 1: serialize the message to a binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mbin_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/serde/serde.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(obj, simplified, force_no_compression, force_no_serialization, force_full_simplification)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0msimple_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_force_full_simplify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0msimple_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_simplify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0msimple_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/serde/serde.py\u001b[0m in \u001b[0;36m_simplify\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0mcurrent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcurrent_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimplifiers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msimplifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/messaging/message.py\u001b[0m in \u001b[0;36msimplify\u001b[0;34m(ptr)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simplify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/serde/serde.py\u001b[0m in \u001b[0;36m_simplify\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0mcurrent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcurrent_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimplifiers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msimplifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/serde/torch_serde.py\u001b[0m in \u001b[0;36m_simplify_torch_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mtensor_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_serialize_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m# note we need to do this explicitly because torch.save does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/serde/torch_serde.py\u001b[0m in \u001b[0;36m_serialize_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_tensor_serializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/serde/torch_serde.py\u001b[0m in \u001b[0;36mtorch_tensor_serializer\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;34m\"\"\"Strategy to serialize a tensor using Torch saver\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mbinary_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0mserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_storages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__reduce_ex__\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce_ex__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mcheck_serializing_named_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;31m# See Note [Don't serialize hooks]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_has_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/_namedtensor_internals.py\u001b[0m in \u001b[0;36mcheck_serializing_named_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_serializing_named_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_BUILD_NAMEDTENSOR\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         raise RuntimeError(\n\u001b[1;32m     21\u001b[0m             \u001b[0;34m\"NYI: Named tensors don't support serialization. Please drop \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __bool__ should return bool, returned Tensor"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model = model.fix_precision().share(*workers, crypto_provider=crypto_provider, requires_grad=True)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "optimizer = optimizer.fix_precision() \n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, private_train_loader, optimizer, epoch)\n",
    "    test(args, model, private_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bf1f2574c48a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/syft-0.1.28a1-py3.7.egg/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self, new_data)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "net = Net().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-acc93b9fb223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "input_test = torch.randn(80, 1, dim).float().cuda()\n",
    "out = net(input_test).cuda()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data into (batch, channel = 1, length=dim)\n",
    "data_torch = torch.from_numpy(x).view([-1, 1, dim]).float()\n",
    "label_torch = torch.from_numpy(y).view([-1,1,1]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 % Trained loss =  tensor(0.7136, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2.0 % Trained loss =  tensor(0.5648, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "3.0 % Trained loss =  tensor(0.3351, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "4.0 % Trained loss =  tensor(0.1074, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "5.0 % Trained loss =  tensor(0.0421, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "6.0 % Trained loss =  tensor(0.0147, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "7.0 % Trained loss =  tensor(0.0081, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "8.0 % Trained loss =  tensor(0.0052, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "9.0 % Trained loss =  tensor(0.0051, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "10.0 % Trained loss =  tensor(0.0032, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "11.0 % Trained loss =  tensor(0.0024, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "12.0 % Trained loss =  tensor(0.0023, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "13.0 % Trained loss =  tensor(0.0024, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "14.0 % Trained loss =  tensor(0.0020, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "15.0 % Trained loss =  tensor(0.0018, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "16.0 % Trained loss =  tensor(0.0020, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "17.0 % Trained loss =  tensor(0.0017, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "18.0 % Trained loss =  tensor(0.0018, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "19.0 % Trained loss =  tensor(0.0015, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "20.0 % Trained loss =  tensor(0.0014, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "21.0 % Trained loss =  tensor(0.0013, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "22.0 % Trained loss =  tensor(0.0013, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "23.0 % Trained loss =  tensor(0.0011, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "24.0 % Trained loss =  tensor(0.0010, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "25.0 % Trained loss =  tensor(0.0011, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "26.0 % Trained loss =  tensor(0.0011, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "27.0 % Trained loss =  tensor(0.0010, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "28.0 % Trained loss =  tensor(0.0009, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "29.0 % Trained loss =  tensor(0.0010, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "30.0 % Trained loss =  tensor(0.0009, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "31.0 % Trained loss =  tensor(0.0009, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "32.0 % Trained loss =  tensor(0.0009, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "33.0 % Trained loss =  tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "34.0 % Trained loss =  tensor(0.0009, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "35.0 % Trained loss =  tensor(0.0008, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "36.0 % Trained loss =  tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "37.0 % Trained loss =  tensor(0.0008, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "38.0 % Trained loss =  tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "39.0 % Trained loss =  tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "40.0 % Trained loss =  tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "41.0 % Trained loss =  tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "42.0 % Trained loss =  tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "43.0 % Trained loss =  tensor(0.0006, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "44.0 % Trained loss =  tensor(0.0006, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "45.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "46.0 % Trained loss =  tensor(0.0006, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "47.0 % Trained loss =  tensor(0.0006, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "48.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "49.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "50.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "51.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "52.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "53.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "54.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "55.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "56.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "57.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "58.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "59.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "60.0 % Trained loss =  tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "61.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "62.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "63.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "64.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "65.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "66.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "67.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "68.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "69.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "70.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "71.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "72.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "73.0 % Trained loss =  tensor(0.0004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "74.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "75.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "76.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "77.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "78.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "79.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "80.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "81.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "82.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "83.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "84.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "85.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "86.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "87.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "88.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "89.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "91.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "92.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "93.0 % Trained loss =  tensor(0.0002, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "94.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "95.0 % Trained loss =  tensor(0.0002, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "96.0 % Trained loss =  tensor(0.0002, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "97.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "98.0 % Trained loss =  tensor(0.0003, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "99.0 % Trained loss =  tensor(0.0002, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "100.0 % Trained loss =  tensor(0.0002, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "test_inputs = torch.from_numpy(x_test).view([-1, 1, dim]).float().cuda()\n",
    "test_labels = torch.from_numpy(y_test).view([-1, 1]).float().cuda()\n",
    "\n",
    "for batch in range(1000):  # loop over the dataset multiple times\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    indices = np.random.choice(len(x_train), size=(30))\n",
    "    inputs = x_train[indices]\n",
    "    labels = y_train[indices]\n",
    "    \n",
    "    inputs = torch.from_numpy(inputs).view([-1, 1, dim]).float().cuda()\n",
    "    labels = torch.from_numpy(labels).view([-1, 1]).float().cuda()\n",
    "    \n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs).view([-1,1]).cuda()\n",
    "    loss = criterion(outputs, labels).cuda()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if batch % 10 == 0:\n",
    "        print(batch / 10 + 1, \"% Trained\", \"loss = \", loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (l1): Linear(in_features=12634, out_features=64, bias=True)\n",
       "  (l2): ReLU()\n",
       "  (r1): Res1d(\n",
       "    (l1): Conv1d(1, 4, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(1, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r2): Res1d(\n",
       "    (l1): Conv1d(4, 8, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(4, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r3): Res1d(\n",
       "    (l1): Conv1d(8, 8, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r4): Res1d(\n",
       "    (l1): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(8, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r5): Res1d(\n",
       "    (l1): Conv1d(16, 16, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(16, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r6): Res1d(\n",
       "    (l1): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(16, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r7): Res1d(\n",
       "    (l1): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r8): Res1d(\n",
       "    (l1): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r9): Res1d(\n",
       "    (l1): Conv1d(64, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r10): Res1d(\n",
       "    (l1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r11): Res1d(\n",
       "    (l1): Conv1d(128, 128, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r12): Res1d(\n",
       "    (l1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r13): Res1d(\n",
       "    (l1): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r14): Res1d(\n",
       "    (l1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r15): Res1d(\n",
       "    (l1): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r16): Res1d(\n",
       "    (l1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r17): Res1d(\n",
       "    (l1): Conv1d(1024, 1024, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (lastLinear): Linear(in_features=50240, out_features=32, bias=True)\n",
       "  (lastRelu): ReLU()\n",
       "  (lastAgg): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (lastSigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MPC learning\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.9235e-04]],\n",
       "\n",
       "        [[2.7360e-04]],\n",
       "\n",
       "        [[1.4392e-04]],\n",
       "\n",
       "        [[3.3061e-04]],\n",
       "\n",
       "        [[1.0315e-04]],\n",
       "\n",
       "        [[3.0822e-04]],\n",
       "\n",
       "        [[2.3279e-04]],\n",
       "\n",
       "        [[2.8794e-04]],\n",
       "\n",
       "        [[2.0224e-04]],\n",
       "\n",
       "        [[2.3346e-04]],\n",
       "\n",
       "        [[2.8597e-04]],\n",
       "\n",
       "        [[2.5769e-04]],\n",
       "\n",
       "        [[3.1846e-04]],\n",
       "\n",
       "        [[2.9116e-04]],\n",
       "\n",
       "        [[2.4118e-04]],\n",
       "\n",
       "        [[3.2269e-04]],\n",
       "\n",
       "        [[3.1257e-04]],\n",
       "\n",
       "        [[2.3454e-04]],\n",
       "\n",
       "        [[2.3503e-04]],\n",
       "\n",
       "        [[3.3291e-04]],\n",
       "\n",
       "        [[1.6589e-04]],\n",
       "\n",
       "        [[2.6916e-04]],\n",
       "\n",
       "        [[3.0157e-04]],\n",
       "\n",
       "        [[1.8384e-04]],\n",
       "\n",
       "        [[1.3061e-04]],\n",
       "\n",
       "        [[2.0306e-04]],\n",
       "\n",
       "        [[2.0023e-04]],\n",
       "\n",
       "        [[2.0535e-04]],\n",
       "\n",
       "        [[2.7104e-04]],\n",
       "\n",
       "        [[2.9693e-04]],\n",
       "\n",
       "        [[3.4671e-04]],\n",
       "\n",
       "        [[3.1465e-04]],\n",
       "\n",
       "        [[1.1507e-04]],\n",
       "\n",
       "        [[2.5428e-04]],\n",
       "\n",
       "        [[2.9876e-04]],\n",
       "\n",
       "        [[3.1614e-04]],\n",
       "\n",
       "        [[1.5914e-04]],\n",
       "\n",
       "        [[1.0949e-04]],\n",
       "\n",
       "        [[3.3419e-04]],\n",
       "\n",
       "        [[2.8547e-04]],\n",
       "\n",
       "        [[2.9799e-04]],\n",
       "\n",
       "        [[2.0596e-04]],\n",
       "\n",
       "        [[3.1286e-04]],\n",
       "\n",
       "        [[3.5396e-04]],\n",
       "\n",
       "        [[2.2458e-04]],\n",
       "\n",
       "        [[9.1964e-05]],\n",
       "\n",
       "        [[4.5097e-05]],\n",
       "\n",
       "        [[1.6480e-04]],\n",
       "\n",
       "        [[1.6132e-04]],\n",
       "\n",
       "        [[1.5180e-04]],\n",
       "\n",
       "        [[2.5887e-04]],\n",
       "\n",
       "        [[1.8588e-04]],\n",
       "\n",
       "        [[1.1208e-04]],\n",
       "\n",
       "        [[2.4590e-04]],\n",
       "\n",
       "        [[2.4481e-04]],\n",
       "\n",
       "        [[3.3715e-04]],\n",
       "\n",
       "        [[2.4364e-04]],\n",
       "\n",
       "        [[2.9804e-04]],\n",
       "\n",
       "        [[2.4933e-04]],\n",
       "\n",
       "        [[2.7982e-04]],\n",
       "\n",
       "        [[3.0472e-04]],\n",
       "\n",
       "        [[2.8638e-04]],\n",
       "\n",
       "        [[2.3667e-04]],\n",
       "\n",
       "        [[1.5964e-04]],\n",
       "\n",
       "        [[2.2699e-04]],\n",
       "\n",
       "        [[3.3432e-04]],\n",
       "\n",
       "        [[1.1735e-04]],\n",
       "\n",
       "        [[2.0138e-04]],\n",
       "\n",
       "        [[1.3726e-04]],\n",
       "\n",
       "        [[1.5344e-04]],\n",
       "\n",
       "        [[2.7559e-04]],\n",
       "\n",
       "        [[1.5775e-04]],\n",
       "\n",
       "        [[3.0523e-04]],\n",
       "\n",
       "        [[2.9573e-04]],\n",
       "\n",
       "        [[2.7232e-04]],\n",
       "\n",
       "        [[2.7350e-04]],\n",
       "\n",
       "        [[4.1519e-04]],\n",
       "\n",
       "        [[3.0074e-04]],\n",
       "\n",
       "        [[1.8282e-04]],\n",
       "\n",
       "        [[3.0792e-04]],\n",
       "\n",
       "        [[2.7813e-04]],\n",
       "\n",
       "        [[3.1668e-04]],\n",
       "\n",
       "        [[3.0468e-04]],\n",
       "\n",
       "        [[3.6079e-04]],\n",
       "\n",
       "        [[9.9973e-01]],\n",
       "\n",
       "        [[9.9982e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9972e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9975e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9989e-01]],\n",
       "\n",
       "        [[9.9983e-01]],\n",
       "\n",
       "        [[9.9986e-01]],\n",
       "\n",
       "        [[9.9969e-01]],\n",
       "\n",
       "        [[9.9972e-01]],\n",
       "\n",
       "        [[9.9972e-01]],\n",
       "\n",
       "        [[9.9971e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9982e-01]],\n",
       "\n",
       "        [[9.9975e-01]],\n",
       "\n",
       "        [[9.9978e-01]],\n",
       "\n",
       "        [[9.9980e-01]],\n",
       "\n",
       "        [[9.9989e-01]],\n",
       "\n",
       "        [[9.9980e-01]],\n",
       "\n",
       "        [[9.9985e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9988e-01]],\n",
       "\n",
       "        [[9.9970e-01]],\n",
       "\n",
       "        [[9.9974e-01]],\n",
       "\n",
       "        [[9.9986e-01]],\n",
       "\n",
       "        [[9.9988e-01]],\n",
       "\n",
       "        [[9.9968e-01]],\n",
       "\n",
       "        [[9.9972e-01]],\n",
       "\n",
       "        [[9.9982e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9978e-01]],\n",
       "\n",
       "        [[9.9986e-01]],\n",
       "\n",
       "        [[9.9962e-01]],\n",
       "\n",
       "        [[9.9981e-01]],\n",
       "\n",
       "        [[9.9980e-01]],\n",
       "\n",
       "        [[9.9983e-01]],\n",
       "\n",
       "        [[9.9978e-01]],\n",
       "\n",
       "        [[9.9968e-01]],\n",
       "\n",
       "        [[9.9973e-01]],\n",
       "\n",
       "        [[9.9973e-01]],\n",
       "\n",
       "        [[9.9980e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9974e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9981e-01]],\n",
       "\n",
       "        [[9.9967e-01]],\n",
       "\n",
       "        [[9.9963e-01]],\n",
       "\n",
       "        [[9.9984e-01]],\n",
       "\n",
       "        [[9.9969e-01]],\n",
       "\n",
       "        [[9.9984e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9972e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9970e-01]],\n",
       "\n",
       "        [[9.9981e-01]],\n",
       "\n",
       "        [[9.9989e-01]],\n",
       "\n",
       "        [[9.9986e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9972e-01]],\n",
       "\n",
       "        [[9.9979e-01]],\n",
       "\n",
       "        [[9.9972e-01]],\n",
       "\n",
       "        [[9.9966e-01]],\n",
       "\n",
       "        [[9.9987e-01]],\n",
       "\n",
       "        [[9.9985e-01]],\n",
       "\n",
       "        [[9.9974e-01]],\n",
       "\n",
       "        [[9.9970e-01]],\n",
       "\n",
       "        [[9.9998e-01]],\n",
       "\n",
       "        [[9.9990e-01]],\n",
       "\n",
       "        [[9.9986e-01]],\n",
       "\n",
       "        [[9.9975e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9981e-01]],\n",
       "\n",
       "        [[9.9976e-01]],\n",
       "\n",
       "        [[9.9993e-01]],\n",
       "\n",
       "        [[9.9966e-01]],\n",
       "\n",
       "        [[9.9969e-01]],\n",
       "\n",
       "        [[9.9983e-01]],\n",
       "\n",
       "        [[9.9979e-01]],\n",
       "\n",
       "        [[9.9965e-01]],\n",
       "\n",
       "        [[9.9981e-01]],\n",
       "\n",
       "        [[9.9979e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9977e-01]],\n",
       "\n",
       "        [[9.9981e-01]],\n",
       "\n",
       "        [[9.9989e-01]],\n",
       "\n",
       "        [[9.9987e-01]],\n",
       "\n",
       "        [[9.9985e-01]],\n",
       "\n",
       "        [[9.9975e-01]],\n",
       "\n",
       "        [[9.9974e-01]],\n",
       "\n",
       "        [[9.9982e-01]],\n",
       "\n",
       "        [[9.9975e-01]],\n",
       "\n",
       "        [[9.9980e-01]],\n",
       "\n",
       "        [[3.1186e-01]],\n",
       "\n",
       "        [[8.8890e-01]],\n",
       "\n",
       "        [[3.0583e-01]],\n",
       "\n",
       "        [[6.9242e-01]],\n",
       "\n",
       "        [[9.1649e-01]],\n",
       "\n",
       "        [[9.1833e-01]],\n",
       "\n",
       "        [[7.0626e-01]],\n",
       "\n",
       "        [[7.0215e-01]],\n",
       "\n",
       "        [[3.4805e-01]],\n",
       "\n",
       "        [[6.0788e-01]],\n",
       "\n",
       "        [[4.5475e-01]],\n",
       "\n",
       "        [[2.3791e-01]],\n",
       "\n",
       "        [[8.1575e-01]],\n",
       "\n",
       "        [[9.8586e-01]],\n",
       "\n",
       "        [[7.6398e-01]],\n",
       "\n",
       "        [[4.6387e-01]],\n",
       "\n",
       "        [[9.3649e-01]],\n",
       "\n",
       "        [[9.2520e-01]],\n",
       "\n",
       "        [[5.7549e-01]],\n",
       "\n",
       "        [[5.6810e-01]],\n",
       "\n",
       "        [[7.9145e-01]],\n",
       "\n",
       "        [[7.8863e-01]],\n",
       "\n",
       "        [[1.3556e-01]],\n",
       "\n",
       "        [[6.5018e-02]],\n",
       "\n",
       "        [[4.3066e-01]],\n",
       "\n",
       "        [[7.7736e-01]],\n",
       "\n",
       "        [[2.2718e-01]],\n",
       "\n",
       "        [[5.6854e-01]],\n",
       "\n",
       "        [[7.3444e-01]],\n",
       "\n",
       "        [[3.3351e-01]],\n",
       "\n",
       "        [[7.7830e-01]],\n",
       "\n",
       "        [[8.7239e-01]],\n",
       "\n",
       "        [[6.7198e-01]],\n",
       "\n",
       "        [[7.0907e-01]],\n",
       "\n",
       "        [[7.2266e-01]],\n",
       "\n",
       "        [[8.0752e-01]],\n",
       "\n",
       "        [[9.4033e-01]],\n",
       "\n",
       "        [[9.0044e-01]],\n",
       "\n",
       "        [[9.0041e-01]],\n",
       "\n",
       "        [[1.6266e-01]],\n",
       "\n",
       "        [[6.3589e-01]],\n",
       "\n",
       "        [[5.0702e-01]],\n",
       "\n",
       "        [[9.4411e-01]],\n",
       "\n",
       "        [[3.0186e-01]],\n",
       "\n",
       "        [[9.8266e-01]],\n",
       "\n",
       "        [[5.5774e-01]]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(data_torch.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
