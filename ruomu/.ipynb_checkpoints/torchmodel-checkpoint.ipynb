{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def getSamples(filename):\n",
    "    data = pd.read_csv(filename, sep='\\t')\n",
    "    return data.values[:,1:].transpose()\n",
    "\n",
    "data1 = getSamples(\"GSE2034-Normal-train.txt\")\n",
    "data2 = getSamples(\"GSE2034-Tumor-train.txt\")\n",
    "\n",
    "data1Label = np.zeros(len(data1)).reshape((-1, 1))\n",
    "data2Label = np.ones(len(data2)).reshape((-1, 1))\n",
    "x = np.concatenate((data1, data2))\n",
    "y = np.concatenate((data1Label, data2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 12634\n",
    "class Res1d(nn.Module):\n",
    "    # the conv layers\n",
    "    def __init__(self, inSize, outSize, kernel=(3,), strides=1,):\n",
    "        super(Res1d, self).__init__()\n",
    "        # hard-coded to do the padding correctly\n",
    "        if inSize in (16,64,128,512) and strides is 2:\n",
    "            pding = 0\n",
    "        else:\n",
    "            pding = 1\n",
    "        self.l1 = nn.Conv1d(inSize, outSize, kernel, stride=strides, padding=pding, bias=False)\n",
    "        self.l2 = nn.InstanceNorm1d(outSize)\n",
    "        \n",
    "        if strides > 1 or inSize != outSize:\n",
    "            if strides > 1:\n",
    "                self.r1 = nn.Identity()\n",
    "                self.r2 = nn.AvgPool1d(strides)\n",
    "            else:\n",
    "                self.r1 = None\n",
    "                self.r2 = None\n",
    "            self.r3 = nn.Conv1d(inSize, outSize, 1, bias=False)\n",
    "            self.r4 = nn.InstanceNorm1d(outSize)\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        l = self.l1(x)\n",
    "        l = self.l2(l)\n",
    "        \n",
    "        if self.r1 is not None:\n",
    "            r = self.r1(x)\n",
    "            r = self.r2(r)\n",
    "            r = self.r3(r)\n",
    "            r = self.r4(r)\n",
    "        else:\n",
    "            r = self.r3(x)\n",
    "            r = self.r4(r)\n",
    "            \n",
    "#         print(self.l1, l.shape, r.shape)\n",
    "        x = l + r\n",
    "        return self.relu(x)\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(dim, 64)\n",
    "        self.l2 = nn.ReLU()\n",
    "        \n",
    "        self.r1 = Res1d(1, 4, 3)\n",
    "        \n",
    "        self.r2 = Res1d(4, 8, 3)\n",
    "        self.r3 = Res1d(8, 8, 3, strides=2)\n",
    "        \n",
    "        self.r4 = Res1d(8, 16, 3)\n",
    "        self.r5 = Res1d(16, 16, 3, strides=2)\n",
    "        \n",
    "        self.r6 = Res1d(16, 32, 3)\n",
    "        self.r7 = Res1d(32, 32, 3, strides=2)\n",
    "        \n",
    "        self.r8 = Res1d(32, 64, 3)\n",
    "        self.r9 = Res1d(64, 64, 3, strides=2)\n",
    "        \n",
    "        self.r10 = Res1d(64, 128, 3)\n",
    "        self.r11 = Res1d(128, 128, 3, strides=2)\n",
    "        \n",
    "        self.r12 = Res1d(128, 256, 3)\n",
    "        self.r13 = Res1d(256, 256, 3, strides=2)\n",
    "        \n",
    "        self.r14 = Res1d(256, 512, 3)\n",
    "        self.r15 = Res1d(512, 512, 3, strides=2)\n",
    "        \n",
    "        self.r16 = Res1d(512, 1024, 3)\n",
    "        self.r17 = Res1d(1024, 1024, 3, strides=2)\n",
    "        \n",
    "        # size is by experiment and hardcode\n",
    "        self.lastLinear = nn.Linear(50240,32)\n",
    "        self.lastRelu = nn.ReLU()\n",
    "        self.lastAgg = nn.Linear(32,1)\n",
    "        self.lastSigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # shape is (batch, channel, time)\n",
    "        l = x\n",
    "        l = self.l2(self.l1(l))\n",
    "        \n",
    "        # conv layers should operate on time\n",
    "        r = x\n",
    "        r = self.r4(self.r3(self.r2(self.r1(r))))\n",
    "        r = self.r8(self.r7(self.r6(self.r5(r))))\n",
    "        r = self.r12(self.r11(self.r10(self.r9(r))))\n",
    "        r = self.r16(self.r15(self.r14(self.r13(r))))\n",
    "        r = self.r17(r)\n",
    "        \n",
    "        # flatten l\n",
    "        r = r.view(x.shape[0],1, -1)\n",
    "        y = torch.cat((l,r),-1)\n",
    "        y = self.lastLinear(y)\n",
    "        y = self.lastRelu(y)\n",
    "        y = self.lastAgg(y)\n",
    "        y = self.lastSigmoid(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test = torch.randn(80, 1, dim).float()\n",
    "out = net(input_test)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data into (batch, channel = 1, length=dim)\n",
    "data_torch = torch.from_numpy(x).view([-1, 1, dim]).float()\n",
    "label_torch = torch.from_numpy(y).view([-1,1,1]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 1000\n",
      "10 out of 1000\n",
      "20 out of 1000\n",
      "30 out of 1000\n",
      "40 out of 1000\n",
      "50 out of 1000\n",
      "60 out of 1000\n",
      "70 out of 1000\n",
      "80 out of 1000\n",
      "90 out of 1000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for batch in range(100):  # loop over the dataset multiple times\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    indices = np.random.choice(len(x), size=(30))\n",
    "    inputs = x[indices]\n",
    "    labels = y[indices]\n",
    "    \n",
    "    inputs = torch.from_numpy(inputs).view([-1, 1, dim]).float()\n",
    "    labels = torch.from_numpy(labels).view([-1, 1]).float()\n",
    "    \n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs).view([-1,1])\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if batch % 10 == 0:\n",
    "        print(batch, \"out of 1000\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (l1): Linear(in_features=12634, out_features=64, bias=True)\n",
       "  (l2): ReLU()\n",
       "  (r1): Res1d(\n",
       "    (l1): Conv1d(1, 4, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(1, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r2): Res1d(\n",
       "    (l1): Conv1d(4, 8, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(4, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r3): Res1d(\n",
       "    (l1): Conv1d(8, 8, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r4): Res1d(\n",
       "    (l1): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(8, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r5): Res1d(\n",
       "    (l1): Conv1d(16, 16, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(16, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r6): Res1d(\n",
       "    (l1): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(16, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r7): Res1d(\n",
       "    (l1): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r8): Res1d(\n",
       "    (l1): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r9): Res1d(\n",
       "    (l1): Conv1d(64, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r10): Res1d(\n",
       "    (l1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r11): Res1d(\n",
       "    (l1): Conv1d(128, 128, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r12): Res1d(\n",
       "    (l1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r13): Res1d(\n",
       "    (l1): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r14): Res1d(\n",
       "    (l1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r15): Res1d(\n",
       "    (l1): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r16): Res1d(\n",
       "    (l1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r17): Res1d(\n",
       "    (l1): Conv1d(1024, 1024, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (lastLinear): Linear(in_features=50240, out_features=32, bias=True)\n",
       "  (lastRelu): ReLU()\n",
       "  (lastAgg): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (lastSigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Run code on CUDA\n",
    "# MPC learning\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0038]],\n",
       "\n",
       "        [[0.0028]],\n",
       "\n",
       "        [[0.0015]],\n",
       "\n",
       "        [[0.0016]],\n",
       "\n",
       "        [[0.0059]],\n",
       "\n",
       "        [[0.0053]],\n",
       "\n",
       "        [[0.0035]],\n",
       "\n",
       "        [[0.0044]],\n",
       "\n",
       "        [[0.0045]],\n",
       "\n",
       "        [[0.0059]],\n",
       "\n",
       "        [[0.0029]],\n",
       "\n",
       "        [[0.0030]],\n",
       "\n",
       "        [[0.0021]],\n",
       "\n",
       "        [[0.0025]],\n",
       "\n",
       "        [[0.0029]],\n",
       "\n",
       "        [[0.0039]],\n",
       "\n",
       "        [[0.0019]],\n",
       "\n",
       "        [[0.0020]],\n",
       "\n",
       "        [[0.0037]],\n",
       "\n",
       "        [[0.0014]],\n",
       "\n",
       "        [[0.0022]],\n",
       "\n",
       "        [[0.0054]],\n",
       "\n",
       "        [[0.0024]],\n",
       "\n",
       "        [[0.0031]],\n",
       "\n",
       "        [[0.0024]],\n",
       "\n",
       "        [[0.0036]],\n",
       "\n",
       "        [[0.0026]],\n",
       "\n",
       "        [[0.0028]],\n",
       "\n",
       "        [[0.0011]],\n",
       "\n",
       "        [[0.0054]],\n",
       "\n",
       "        [[0.0021]],\n",
       "\n",
       "        [[0.0030]],\n",
       "\n",
       "        [[0.0057]],\n",
       "\n",
       "        [[0.0053]],\n",
       "\n",
       "        [[0.0102]],\n",
       "\n",
       "        [[0.0044]],\n",
       "\n",
       "        [[0.0044]],\n",
       "\n",
       "        [[0.0011]],\n",
       "\n",
       "        [[0.0044]],\n",
       "\n",
       "        [[0.0028]],\n",
       "\n",
       "        [[0.0020]],\n",
       "\n",
       "        [[0.0030]],\n",
       "\n",
       "        [[0.0048]],\n",
       "\n",
       "        [[0.0021]],\n",
       "\n",
       "        [[0.0026]],\n",
       "\n",
       "        [[0.0025]],\n",
       "\n",
       "        [[0.0053]],\n",
       "\n",
       "        [[0.0036]],\n",
       "\n",
       "        [[0.0024]],\n",
       "\n",
       "        [[0.0023]],\n",
       "\n",
       "        [[0.0025]],\n",
       "\n",
       "        [[0.0028]],\n",
       "\n",
       "        [[0.0066]],\n",
       "\n",
       "        [[0.0057]],\n",
       "\n",
       "        [[0.0017]],\n",
       "\n",
       "        [[0.0025]],\n",
       "\n",
       "        [[0.0037]],\n",
       "\n",
       "        [[0.0018]],\n",
       "\n",
       "        [[0.0036]],\n",
       "\n",
       "        [[0.0017]],\n",
       "\n",
       "        [[0.0020]],\n",
       "\n",
       "        [[0.0017]],\n",
       "\n",
       "        [[0.0038]],\n",
       "\n",
       "        [[0.0032]],\n",
       "\n",
       "        [[0.0012]],\n",
       "\n",
       "        [[0.0087]],\n",
       "\n",
       "        [[0.0026]],\n",
       "\n",
       "        [[0.0037]],\n",
       "\n",
       "        [[0.0013]],\n",
       "\n",
       "        [[0.0015]],\n",
       "\n",
       "        [[0.0034]],\n",
       "\n",
       "        [[0.0015]],\n",
       "\n",
       "        [[0.0039]],\n",
       "\n",
       "        [[0.0056]],\n",
       "\n",
       "        [[0.0020]],\n",
       "\n",
       "        [[0.0019]],\n",
       "\n",
       "        [[0.0049]],\n",
       "\n",
       "        [[0.0070]],\n",
       "\n",
       "        [[0.0040]],\n",
       "\n",
       "        [[0.0031]],\n",
       "\n",
       "        [[0.0051]],\n",
       "\n",
       "        [[0.0017]],\n",
       "\n",
       "        [[0.0021]],\n",
       "\n",
       "        [[0.0050]],\n",
       "\n",
       "        [[0.9903]],\n",
       "\n",
       "        [[0.9981]],\n",
       "\n",
       "        [[0.9993]],\n",
       "\n",
       "        [[0.9947]],\n",
       "\n",
       "        [[0.9989]],\n",
       "\n",
       "        [[0.9966]],\n",
       "\n",
       "        [[0.9980]],\n",
       "\n",
       "        [[0.9989]],\n",
       "\n",
       "        [[0.9987]],\n",
       "\n",
       "        [[0.9902]],\n",
       "\n",
       "        [[0.9965]],\n",
       "\n",
       "        [[0.9944]],\n",
       "\n",
       "        [[0.9979]],\n",
       "\n",
       "        [[0.9981]],\n",
       "\n",
       "        [[0.9988]],\n",
       "\n",
       "        [[0.9993]],\n",
       "\n",
       "        [[0.9945]],\n",
       "\n",
       "        [[0.9925]],\n",
       "\n",
       "        [[0.9976]],\n",
       "\n",
       "        [[0.9904]],\n",
       "\n",
       "        [[0.9968]],\n",
       "\n",
       "        [[0.9969]],\n",
       "\n",
       "        [[0.9986]],\n",
       "\n",
       "        [[0.9995]],\n",
       "\n",
       "        [[0.9973]],\n",
       "\n",
       "        [[0.9958]],\n",
       "\n",
       "        [[0.9955]],\n",
       "\n",
       "        [[0.9949]],\n",
       "\n",
       "        [[0.9994]],\n",
       "\n",
       "        [[0.9988]],\n",
       "\n",
       "        [[0.9984]],\n",
       "\n",
       "        [[0.9975]],\n",
       "\n",
       "        [[0.9923]],\n",
       "\n",
       "        [[0.9989]],\n",
       "\n",
       "        [[0.9952]],\n",
       "\n",
       "        [[0.9979]],\n",
       "\n",
       "        [[0.9948]],\n",
       "\n",
       "        [[0.9998]],\n",
       "\n",
       "        [[0.9986]],\n",
       "\n",
       "        [[0.9906]],\n",
       "\n",
       "        [[0.9971]],\n",
       "\n",
       "        [[0.9988]],\n",
       "\n",
       "        [[0.9995]],\n",
       "\n",
       "        [[0.9996]],\n",
       "\n",
       "        [[0.9972]],\n",
       "\n",
       "        [[0.9916]],\n",
       "\n",
       "        [[0.9957]],\n",
       "\n",
       "        [[0.9976]],\n",
       "\n",
       "        [[0.9993]],\n",
       "\n",
       "        [[0.9983]],\n",
       "\n",
       "        [[0.9851]],\n",
       "\n",
       "        [[0.9932]],\n",
       "\n",
       "        [[0.9938]],\n",
       "\n",
       "        [[0.9997]],\n",
       "\n",
       "        [[0.9963]],\n",
       "\n",
       "        [[0.9937]],\n",
       "\n",
       "        [[0.9994]],\n",
       "\n",
       "        [[0.9976]],\n",
       "\n",
       "        [[0.9970]],\n",
       "\n",
       "        [[0.9991]],\n",
       "\n",
       "        [[0.9935]],\n",
       "\n",
       "        [[0.9944]],\n",
       "\n",
       "        [[0.9991]],\n",
       "\n",
       "        [[0.9987]],\n",
       "\n",
       "        [[0.9987]],\n",
       "\n",
       "        [[0.9997]],\n",
       "\n",
       "        [[0.9944]],\n",
       "\n",
       "        [[0.9975]],\n",
       "\n",
       "        [[0.9990]],\n",
       "\n",
       "        [[0.9978]],\n",
       "\n",
       "        [[0.9983]],\n",
       "\n",
       "        [[0.9991]],\n",
       "\n",
       "        [[0.9989]],\n",
       "\n",
       "        [[0.9993]],\n",
       "\n",
       "        [[0.9986]],\n",
       "\n",
       "        [[0.9983]],\n",
       "\n",
       "        [[0.9977]],\n",
       "\n",
       "        [[0.9985]],\n",
       "\n",
       "        [[0.9869]],\n",
       "\n",
       "        [[0.9971]],\n",
       "\n",
       "        [[0.9947]],\n",
       "\n",
       "        [[0.9996]],\n",
       "\n",
       "        [[0.9982]],\n",
       "\n",
       "        [[0.9978]],\n",
       "\n",
       "        [[0.9990]],\n",
       "\n",
       "        [[0.9980]],\n",
       "\n",
       "        [[0.9992]],\n",
       "\n",
       "        [[0.9853]],\n",
       "\n",
       "        [[0.9966]],\n",
       "\n",
       "        [[0.9950]],\n",
       "\n",
       "        [[0.9965]],\n",
       "\n",
       "        [[0.9992]],\n",
       "\n",
       "        [[0.9893]],\n",
       "\n",
       "        [[0.9858]],\n",
       "\n",
       "        [[0.9970]],\n",
       "\n",
       "        [[0.9979]],\n",
       "\n",
       "        [[0.9981]],\n",
       "\n",
       "        [[0.9958]],\n",
       "\n",
       "        [[0.9983]],\n",
       "\n",
       "        [[0.9969]],\n",
       "\n",
       "        [[0.9996]],\n",
       "\n",
       "        [[0.9977]],\n",
       "\n",
       "        [[0.9976]],\n",
       "\n",
       "        [[0.9984]],\n",
       "\n",
       "        [[0.9972]],\n",
       "\n",
       "        [[0.9984]],\n",
       "\n",
       "        [[0.9973]],\n",
       "\n",
       "        [[0.9979]],\n",
       "\n",
       "        [[0.9983]],\n",
       "\n",
       "        [[0.9980]],\n",
       "\n",
       "        [[0.9990]],\n",
       "\n",
       "        [[0.9960]],\n",
       "\n",
       "        [[0.9948]],\n",
       "\n",
       "        [[0.9990]],\n",
       "\n",
       "        [[0.9993]],\n",
       "\n",
       "        [[0.9969]],\n",
       "\n",
       "        [[0.9994]],\n",
       "\n",
       "        [[0.9979]],\n",
       "\n",
       "        [[0.9971]],\n",
       "\n",
       "        [[0.9978]],\n",
       "\n",
       "        [[0.9962]],\n",
       "\n",
       "        [[0.9988]],\n",
       "\n",
       "        [[0.9989]],\n",
       "\n",
       "        [[0.9946]],\n",
       "\n",
       "        [[0.9971]],\n",
       "\n",
       "        [[0.9976]],\n",
       "\n",
       "        [[0.9917]],\n",
       "\n",
       "        [[0.9914]],\n",
       "\n",
       "        [[0.9953]],\n",
       "\n",
       "        [[0.9990]],\n",
       "\n",
       "        [[0.9973]],\n",
       "\n",
       "        [[0.9990]],\n",
       "\n",
       "        [[0.9850]],\n",
       "\n",
       "        [[0.9977]],\n",
       "\n",
       "        [[0.9976]],\n",
       "\n",
       "        [[0.9982]],\n",
       "\n",
       "        [[0.9929]],\n",
       "\n",
       "        [[0.9982]],\n",
       "\n",
       "        [[0.9995]],\n",
       "\n",
       "        [[0.9985]],\n",
       "\n",
       "        [[0.9982]],\n",
       "\n",
       "        [[0.9991]],\n",
       "\n",
       "        [[0.9902]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(data_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
