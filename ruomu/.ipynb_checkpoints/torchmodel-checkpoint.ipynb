{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def getSamples(filename):\n",
    "    data = pd.read_csv(filename, sep='\\t')\n",
    "    return data.values[:,1:].transpose()\n",
    "\n",
    "data1 = getSamples(\"GSE2034-Normal-train.txt\")\n",
    "data2 = getSamples(\"GSE2034-Tumor-train.txt\")\n",
    "\n",
    "data1Label = np.zeros(len(data1)).reshape((-1, 1))\n",
    "data2Label = np.ones(len(data2)).reshape((-1, 1))\n",
    "x = np.concatenate((data1, data2))\n",
    "y = np.concatenate((data1Label, data2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 12634\n",
    "class Res1d(nn.Module):\n",
    "    # the conv layers\n",
    "    def __init__(self, inSize, outSize, kernel=(3,), strides=1,):\n",
    "        super(Res1d, self).__init__()\n",
    "        # hard-coded to do the padding correctly\n",
    "        if inSize in (16,64,128,512) and strides is 2:\n",
    "            pding = 0\n",
    "        else:\n",
    "            pding = 1\n",
    "        self.l1 = nn.Conv1d(inSize, outSize, kernel, stride=strides, padding=pding, bias=False)\n",
    "        self.l2 = nn.InstanceNorm1d(outSize)\n",
    "        \n",
    "        if strides > 1 or inSize != outSize:\n",
    "            if strides > 1:\n",
    "                self.r1 = nn.Identity()\n",
    "                self.r2 = nn.AvgPool1d(strides)\n",
    "            else:\n",
    "                self.r1 = None\n",
    "                self.r2 = None\n",
    "            self.r3 = nn.Conv1d(inSize, outSize, 1, bias=False)\n",
    "            self.r4 = nn.InstanceNorm1d(outSize)\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        l = self.l1(x)\n",
    "        l = self.l2(l)\n",
    "        \n",
    "        if self.r1 is not None:\n",
    "            r = self.r1(x)\n",
    "            r = self.r2(r)\n",
    "            r = self.r3(r)\n",
    "            r = self.r4(r)\n",
    "        else:\n",
    "            r = self.r3(x)\n",
    "            r = self.r4(r)\n",
    "            \n",
    "#         print(self.l1, l.shape, r.shape)\n",
    "        x = l + r\n",
    "        return self.relu(x)\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(dim, 64)\n",
    "        self.l2 = nn.ReLU()\n",
    "        \n",
    "        self.r1 = Res1d(1, 4, 3)\n",
    "        \n",
    "        self.r2 = Res1d(4, 8, 3)\n",
    "        self.r3 = Res1d(8, 8, 3, strides=2)\n",
    "        \n",
    "        self.r4 = Res1d(8, 16, 3)\n",
    "        self.r5 = Res1d(16, 16, 3, strides=2)\n",
    "        \n",
    "        self.r6 = Res1d(16, 32, 3)\n",
    "        self.r7 = Res1d(32, 32, 3, strides=2)\n",
    "        \n",
    "        self.r8 = Res1d(32, 64, 3)\n",
    "        self.r9 = Res1d(64, 64, 3, strides=2)\n",
    "        \n",
    "        self.r10 = Res1d(64, 128, 3)\n",
    "        self.r11 = Res1d(128, 128, 3, strides=2)\n",
    "        \n",
    "        self.r12 = Res1d(128, 256, 3)\n",
    "        self.r13 = Res1d(256, 256, 3, strides=2)\n",
    "        \n",
    "        self.r14 = Res1d(256, 512, 3)\n",
    "        self.r15 = Res1d(512, 512, 3, strides=2)\n",
    "        \n",
    "        self.r16 = Res1d(512, 1024, 3)\n",
    "        self.r17 = Res1d(1024, 1024, 3, strides=2)\n",
    "        \n",
    "        # size is by experiment and hardcode\n",
    "        self.lastLinear = nn.Linear(50240,32)\n",
    "        self.lastRelu = nn.ReLU()\n",
    "        self.lastAgg = nn.Linear(32,1)\n",
    "        self.lastSigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # shape is (batch, channel, time)\n",
    "        l = x\n",
    "        l = self.l2(self.l1(l))\n",
    "        \n",
    "        # conv layers should operate on time\n",
    "        r = x\n",
    "        r = self.r4(self.r3(self.r2(self.r1(r))))\n",
    "        r = self.r8(self.r7(self.r6(self.r5(r))))\n",
    "        r = self.r12(self.r11(self.r10(self.r9(r))))\n",
    "        r = self.r16(self.r15(self.r14(self.r13(r))))\n",
    "        r = self.r17(r)\n",
    "        \n",
    "        # flatten l\n",
    "        r = r.view(x.shape[0],1, -1)\n",
    "        y = torch.cat((l,r),-1)\n",
    "        y = self.lastLinear(y)\n",
    "        y = self.lastRelu(y)\n",
    "        y = self.lastAgg(y)\n",
    "        y = self.lastSigmoid(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "net = Net().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test = torch.randn(80, 1, dim).float().cuda()\n",
    "out = net(input_test).cuda()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data into (batch, channel = 1, length=dim)\n",
    "data_torch = torch.from_numpy(x).view([-1, 1, dim]).float()\n",
    "label_torch = torch.from_numpy(y).view([-1,1,1]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 % Trained\n",
      "1 % Trained\n",
      "2 % Trained\n",
      "3 % Trained\n",
      "4 % Trained\n",
      "5 % Trained\n",
      "6 % Trained\n",
      "7 % Trained\n",
      "8 % Trained\n",
      "9 % Trained\n",
      "10 % Trained\n",
      "11 % Trained\n",
      "12 % Trained\n",
      "13 % Trained\n",
      "14 % Trained\n",
      "15 % Trained\n",
      "16 % Trained\n",
      "17 % Trained\n",
      "18 % Trained\n",
      "19 % Trained\n",
      "20 % Trained\n",
      "21 % Trained\n",
      "22 % Trained\n",
      "23 % Trained\n",
      "24 % Trained\n",
      "25 % Trained\n",
      "26 % Trained\n",
      "27 % Trained\n",
      "28 % Trained\n",
      "29 % Trained\n",
      "30 % Trained\n",
      "31 % Trained\n",
      "32 % Trained\n",
      "33 % Trained\n",
      "34 % Trained\n",
      "35 % Trained\n",
      "36 % Trained\n",
      "37 % Trained\n",
      "38 % Trained\n",
      "39 % Trained\n",
      "40 % Trained\n",
      "41 % Trained\n",
      "42 % Trained\n",
      "43 % Trained\n",
      "44 % Trained\n",
      "45 % Trained\n",
      "46 % Trained\n",
      "47 % Trained\n",
      "48 % Trained\n",
      "49 % Trained\n",
      "50 % Trained\n",
      "51 % Trained\n",
      "52 % Trained\n",
      "53 % Trained\n",
      "54 % Trained\n",
      "55 % Trained\n",
      "56 % Trained\n",
      "57 % Trained\n",
      "58 % Trained\n",
      "59 % Trained\n",
      "60 % Trained\n",
      "61 % Trained\n",
      "62 % Trained\n",
      "63 % Trained\n",
      "64 % Trained\n",
      "65 % Trained\n",
      "66 % Trained\n",
      "67 % Trained\n",
      "68 % Trained\n",
      "69 % Trained\n",
      "70 % Trained\n",
      "71 % Trained\n",
      "72 % Trained\n",
      "73 % Trained\n",
      "74 % Trained\n",
      "75 % Trained\n",
      "76 % Trained\n",
      "77 % Trained\n",
      "78 % Trained\n",
      "79 % Trained\n",
      "80 % Trained\n",
      "81 % Trained\n",
      "82 % Trained\n",
      "83 % Trained\n",
      "84 % Trained\n",
      "85 % Trained\n",
      "86 % Trained\n",
      "87 % Trained\n",
      "88 % Trained\n",
      "89 % Trained\n",
      "90 % Trained\n",
      "91 % Trained\n",
      "92 % Trained\n",
      "93 % Trained\n",
      "94 % Trained\n",
      "95 % Trained\n",
      "96 % Trained\n",
      "97 % Trained\n",
      "98 % Trained\n",
      "99 % Trained\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for batch in range(100):  # loop over the dataset multiple times\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    indices = np.random.choice(len(x), size=(30))\n",
    "    inputs = x[indices]\n",
    "    labels = y[indices]\n",
    "    \n",
    "    inputs = torch.from_numpy(inputs).view([-1, 1, dim]).float().cuda()\n",
    "    labels = torch.from_numpy(labels).view([-1, 1]).float().cuda()\n",
    "    \n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs).view([-1,1]).cuda()\n",
    "    loss = criterion(outputs, labels).cuda()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #if batch % 10 == 0:\n",
    "    print(batch, \"% Trained\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (l1): Linear(in_features=12634, out_features=64, bias=True)\n",
       "  (l2): ReLU()\n",
       "  (r1): Res1d(\n",
       "    (l1): Conv1d(1, 4, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(1, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r2): Res1d(\n",
       "    (l1): Conv1d(4, 8, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(4, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r3): Res1d(\n",
       "    (l1): Conv1d(8, 8, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r4): Res1d(\n",
       "    (l1): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(8, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r5): Res1d(\n",
       "    (l1): Conv1d(16, 16, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(16, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r6): Res1d(\n",
       "    (l1): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(16, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r7): Res1d(\n",
       "    (l1): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r8): Res1d(\n",
       "    (l1): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r9): Res1d(\n",
       "    (l1): Conv1d(64, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r10): Res1d(\n",
       "    (l1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r11): Res1d(\n",
       "    (l1): Conv1d(128, 128, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r12): Res1d(\n",
       "    (l1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r13): Res1d(\n",
       "    (l1): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r14): Res1d(\n",
       "    (l1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r15): Res1d(\n",
       "    (l1): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "    (l2): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r16): Res1d(\n",
       "    (l1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (r17): Res1d(\n",
       "    (l1): Conv1d(1024, 1024, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (l2): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (r1): Identity()\n",
       "    (r2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (r3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (r4): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (lastLinear): Linear(in_features=50240, out_features=32, bias=True)\n",
       "  (lastRelu): ReLU()\n",
       "  (lastAgg): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (lastSigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MPC learning\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5.5693e-03]],\n",
       "\n",
       "        [[1.2892e-02]],\n",
       "\n",
       "        [[3.3465e-03]],\n",
       "\n",
       "        [[4.2194e-04]],\n",
       "\n",
       "        [[4.5199e-03]],\n",
       "\n",
       "        [[5.4603e-03]],\n",
       "\n",
       "        [[4.1989e-03]],\n",
       "\n",
       "        [[1.0753e-02]],\n",
       "\n",
       "        [[5.1220e-03]],\n",
       "\n",
       "        [[5.5587e-03]],\n",
       "\n",
       "        [[3.8188e-03]],\n",
       "\n",
       "        [[2.6553e-03]],\n",
       "\n",
       "        [[4.9701e-03]],\n",
       "\n",
       "        [[3.5327e-03]],\n",
       "\n",
       "        [[9.2005e-03]],\n",
       "\n",
       "        [[5.1572e-03]],\n",
       "\n",
       "        [[2.5510e-03]],\n",
       "\n",
       "        [[4.8186e-03]],\n",
       "\n",
       "        [[6.3429e-03]],\n",
       "\n",
       "        [[2.2609e-03]],\n",
       "\n",
       "        [[1.8099e-03]],\n",
       "\n",
       "        [[5.7676e-03]],\n",
       "\n",
       "        [[3.3225e-03]],\n",
       "\n",
       "        [[4.9803e-03]],\n",
       "\n",
       "        [[3.2558e-03]],\n",
       "\n",
       "        [[1.9185e-03]],\n",
       "\n",
       "        [[1.9541e-03]],\n",
       "\n",
       "        [[7.1851e-03]],\n",
       "\n",
       "        [[3.5984e-03]],\n",
       "\n",
       "        [[7.4177e-03]],\n",
       "\n",
       "        [[2.3416e-02]],\n",
       "\n",
       "        [[6.9360e-03]],\n",
       "\n",
       "        [[3.9892e-03]],\n",
       "\n",
       "        [[1.5723e-02]],\n",
       "\n",
       "        [[5.1656e-03]],\n",
       "\n",
       "        [[4.1250e-03]],\n",
       "\n",
       "        [[8.3235e-03]],\n",
       "\n",
       "        [[2.9352e-03]],\n",
       "\n",
       "        [[2.8757e-03]],\n",
       "\n",
       "        [[4.7430e-03]],\n",
       "\n",
       "        [[2.5916e-03]],\n",
       "\n",
       "        [[7.0799e-03]],\n",
       "\n",
       "        [[6.0035e-03]],\n",
       "\n",
       "        [[4.5568e-03]],\n",
       "\n",
       "        [[6.3126e-03]],\n",
       "\n",
       "        [[4.3705e-03]],\n",
       "\n",
       "        [[1.4089e-02]],\n",
       "\n",
       "        [[3.8019e-03]],\n",
       "\n",
       "        [[5.6014e-03]],\n",
       "\n",
       "        [[3.5935e-03]],\n",
       "\n",
       "        [[1.8205e-03]],\n",
       "\n",
       "        [[3.5122e-03]],\n",
       "\n",
       "        [[8.2090e-03]],\n",
       "\n",
       "        [[6.2791e-03]],\n",
       "\n",
       "        [[4.1298e-03]],\n",
       "\n",
       "        [[9.5029e-03]],\n",
       "\n",
       "        [[1.4069e-02]],\n",
       "\n",
       "        [[4.7769e-03]],\n",
       "\n",
       "        [[4.8082e-03]],\n",
       "\n",
       "        [[7.3227e-03]],\n",
       "\n",
       "        [[3.0000e-03]],\n",
       "\n",
       "        [[4.5944e-03]],\n",
       "\n",
       "        [[5.0221e-03]],\n",
       "\n",
       "        [[1.1562e-03]],\n",
       "\n",
       "        [[6.7949e-03]],\n",
       "\n",
       "        [[6.1435e-03]],\n",
       "\n",
       "        [[3.0443e-03]],\n",
       "\n",
       "        [[3.8762e-03]],\n",
       "\n",
       "        [[2.6531e-03]],\n",
       "\n",
       "        [[5.5099e-03]],\n",
       "\n",
       "        [[8.4202e-03]],\n",
       "\n",
       "        [[4.9825e-03]],\n",
       "\n",
       "        [[6.9421e-03]],\n",
       "\n",
       "        [[1.0916e-02]],\n",
       "\n",
       "        [[6.6037e-03]],\n",
       "\n",
       "        [[3.0068e-03]],\n",
       "\n",
       "        [[6.1640e-03]],\n",
       "\n",
       "        [[1.2663e-02]],\n",
       "\n",
       "        [[2.1570e-03]],\n",
       "\n",
       "        [[4.0176e-03]],\n",
       "\n",
       "        [[6.8523e-03]],\n",
       "\n",
       "        [[2.9209e-03]],\n",
       "\n",
       "        [[6.2360e-03]],\n",
       "\n",
       "        [[6.6680e-03]],\n",
       "\n",
       "        [[9.9614e-01]],\n",
       "\n",
       "        [[9.9657e-01]],\n",
       "\n",
       "        [[9.9798e-01]],\n",
       "\n",
       "        [[9.9669e-01]],\n",
       "\n",
       "        [[9.9668e-01]],\n",
       "\n",
       "        [[9.9846e-01]],\n",
       "\n",
       "        [[9.9823e-01]],\n",
       "\n",
       "        [[9.9813e-01]],\n",
       "\n",
       "        [[9.9508e-01]],\n",
       "\n",
       "        [[9.9852e-01]],\n",
       "\n",
       "        [[9.9318e-01]],\n",
       "\n",
       "        [[9.9673e-01]],\n",
       "\n",
       "        [[9.9895e-01]],\n",
       "\n",
       "        [[9.9803e-01]],\n",
       "\n",
       "        [[9.9490e-01]],\n",
       "\n",
       "        [[9.9714e-01]],\n",
       "\n",
       "        [[9.9417e-01]],\n",
       "\n",
       "        [[9.9651e-01]],\n",
       "\n",
       "        [[9.9760e-01]],\n",
       "\n",
       "        [[9.9598e-01]],\n",
       "\n",
       "        [[9.9856e-01]],\n",
       "\n",
       "        [[9.9502e-01]],\n",
       "\n",
       "        [[9.9843e-01]],\n",
       "\n",
       "        [[9.9783e-01]],\n",
       "\n",
       "        [[9.9348e-01]],\n",
       "\n",
       "        [[9.9358e-01]],\n",
       "\n",
       "        [[9.9834e-01]],\n",
       "\n",
       "        [[9.9932e-01]],\n",
       "\n",
       "        [[9.9517e-01]],\n",
       "\n",
       "        [[9.9781e-01]],\n",
       "\n",
       "        [[9.9890e-01]],\n",
       "\n",
       "        [[9.9661e-01]],\n",
       "\n",
       "        [[9.9759e-01]],\n",
       "\n",
       "        [[9.9568e-01]],\n",
       "\n",
       "        [[9.9801e-01]],\n",
       "\n",
       "        [[9.9515e-01]],\n",
       "\n",
       "        [[9.9631e-01]],\n",
       "\n",
       "        [[9.9942e-01]],\n",
       "\n",
       "        [[9.9831e-01]],\n",
       "\n",
       "        [[9.9294e-01]],\n",
       "\n",
       "        [[9.9907e-01]],\n",
       "\n",
       "        [[9.8689e-01]],\n",
       "\n",
       "        [[9.9828e-01]],\n",
       "\n",
       "        [[9.9629e-01]],\n",
       "\n",
       "        [[9.9380e-01]],\n",
       "\n",
       "        [[9.9466e-01]],\n",
       "\n",
       "        [[9.9643e-01]],\n",
       "\n",
       "        [[9.9590e-01]],\n",
       "\n",
       "        [[9.9868e-01]],\n",
       "\n",
       "        [[9.9878e-01]],\n",
       "\n",
       "        [[9.9508e-01]],\n",
       "\n",
       "        [[9.9895e-01]],\n",
       "\n",
       "        [[9.9870e-01]],\n",
       "\n",
       "        [[9.9788e-01]],\n",
       "\n",
       "        [[9.9845e-01]],\n",
       "\n",
       "        [[9.9265e-01]],\n",
       "\n",
       "        [[9.9782e-01]],\n",
       "\n",
       "        [[9.9607e-01]],\n",
       "\n",
       "        [[9.9686e-01]],\n",
       "\n",
       "        [[9.9914e-01]],\n",
       "\n",
       "        [[9.9730e-01]],\n",
       "\n",
       "        [[9.9786e-01]],\n",
       "\n",
       "        [[9.9732e-01]],\n",
       "\n",
       "        [[9.9543e-01]],\n",
       "\n",
       "        [[9.9790e-01]],\n",
       "\n",
       "        [[9.9736e-01]],\n",
       "\n",
       "        [[9.9667e-01]],\n",
       "\n",
       "        [[9.9754e-01]],\n",
       "\n",
       "        [[9.9863e-01]],\n",
       "\n",
       "        [[9.9811e-01]],\n",
       "\n",
       "        [[9.9508e-01]],\n",
       "\n",
       "        [[9.9400e-01]],\n",
       "\n",
       "        [[9.9421e-01]],\n",
       "\n",
       "        [[9.9433e-01]],\n",
       "\n",
       "        [[9.9305e-01]],\n",
       "\n",
       "        [[9.9870e-01]],\n",
       "\n",
       "        [[9.9310e-01]],\n",
       "\n",
       "        [[9.9607e-01]],\n",
       "\n",
       "        [[9.9137e-01]],\n",
       "\n",
       "        [[9.9645e-01]],\n",
       "\n",
       "        [[9.9701e-01]],\n",
       "\n",
       "        [[9.9867e-01]],\n",
       "\n",
       "        [[9.9614e-01]],\n",
       "\n",
       "        [[9.9839e-01]],\n",
       "\n",
       "        [[9.9736e-01]],\n",
       "\n",
       "        [[9.9268e-01]],\n",
       "\n",
       "        [[9.9809e-01]],\n",
       "\n",
       "        [[9.9150e-01]],\n",
       "\n",
       "        [[9.9695e-01]],\n",
       "\n",
       "        [[9.9855e-01]],\n",
       "\n",
       "        [[9.9824e-01]],\n",
       "\n",
       "        [[9.9624e-01]],\n",
       "\n",
       "        [[9.9873e-01]],\n",
       "\n",
       "        [[9.9711e-01]],\n",
       "\n",
       "        [[9.9702e-01]],\n",
       "\n",
       "        [[9.9232e-01]],\n",
       "\n",
       "        [[9.9576e-01]],\n",
       "\n",
       "        [[9.9785e-01]],\n",
       "\n",
       "        [[9.9781e-01]],\n",
       "\n",
       "        [[9.9549e-01]],\n",
       "\n",
       "        [[9.9694e-01]],\n",
       "\n",
       "        [[9.9721e-01]],\n",
       "\n",
       "        [[9.9784e-01]],\n",
       "\n",
       "        [[9.9235e-01]],\n",
       "\n",
       "        [[9.9648e-01]],\n",
       "\n",
       "        [[9.9754e-01]],\n",
       "\n",
       "        [[9.9881e-01]],\n",
       "\n",
       "        [[9.9824e-01]],\n",
       "\n",
       "        [[9.9833e-01]],\n",
       "\n",
       "        [[9.9833e-01]],\n",
       "\n",
       "        [[9.9939e-01]],\n",
       "\n",
       "        [[9.9837e-01]],\n",
       "\n",
       "        [[9.9690e-01]],\n",
       "\n",
       "        [[9.9696e-01]],\n",
       "\n",
       "        [[9.9931e-01]],\n",
       "\n",
       "        [[9.9661e-01]],\n",
       "\n",
       "        [[9.9728e-01]],\n",
       "\n",
       "        [[9.9831e-01]],\n",
       "\n",
       "        [[9.9715e-01]],\n",
       "\n",
       "        [[9.9709e-01]],\n",
       "\n",
       "        [[9.9555e-01]],\n",
       "\n",
       "        [[9.9666e-01]],\n",
       "\n",
       "        [[9.9675e-01]],\n",
       "\n",
       "        [[9.9731e-01]],\n",
       "\n",
       "        [[9.9816e-01]],\n",
       "\n",
       "        [[9.9814e-01]],\n",
       "\n",
       "        [[9.9661e-01]],\n",
       "\n",
       "        [[9.9665e-01]],\n",
       "\n",
       "        [[9.9832e-01]],\n",
       "\n",
       "        [[9.9617e-01]],\n",
       "\n",
       "        [[9.9767e-01]],\n",
       "\n",
       "        [[9.9463e-01]],\n",
       "\n",
       "        [[9.9465e-01]],\n",
       "\n",
       "        [[9.9882e-01]],\n",
       "\n",
       "        [[9.9724e-01]],\n",
       "\n",
       "        [[9.8974e-01]],\n",
       "\n",
       "        [[9.9824e-01]],\n",
       "\n",
       "        [[9.9804e-01]],\n",
       "\n",
       "        [[9.9739e-01]],\n",
       "\n",
       "        [[9.9901e-01]],\n",
       "\n",
       "        [[9.9804e-01]],\n",
       "\n",
       "        [[9.9927e-01]],\n",
       "\n",
       "        [[9.9893e-01]]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(data_torch.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
