\documentclass[a4paper,12pt]{article}

\usepackage[english]{babel}
\usepackage{blindtext}
\usepackage[a4paper, inner=1.7cm, outer=2.7cm, top=2cm, bottom=2cm, bindingoffset=1.2cm]{geometry}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{index}
\usepackage{listings}
\usepackage{minted}

\newcommand{\torch}{\texttt{Pytorch}}
\begin{document}
\title{\Large{\textbf{Secure Collaborative Training of Machine Learning Model using MPC}}}
\author{By Souhail Meftah, Ruomu Hou}
\date{October 22, 2019}
\maketitle
\let\cleardoublepage\clearpage
%\tableofcontents
\setcounter{page}{1}
\fancyhf{}



\section{Background and Motivation}
The advance in machine learning that was driven by the wide application of neural networks has brought automation to a new level. Neural networks are deployed to replace human in making financial decisions, medical image processing and many tasks that were once believed to be `of higher intelligent requirement' and hence not solvable by machines. However, the seemingly magical power of machine learning is not a magic but often relies on carefully crafted models and massive labelled training data to function. Under the hood of `artificial intelligence', neural networks are essentially fitting massively parameterized generic models to specific functions. Hence, a huge amount of data which were previously studied and labelled is used to `teach' neural network models to `learn' the decision functions.

As the decisions made by neural network getting more complicated and increasingly mission-critical, it poses a higher requirement not only on the scale of the data (e.g. it is not uncommon to find PB sized database being used in training AI nowadays) but also on the specificity of the data. For instance, even prior to the emerge of neural network, banks have been using generic data, such as age and credit records to make decisions for loans, but nowadays banks are using more complicated data, such as social network posts, consumption behaviour and even facial expressions to make much more accurate decisions with the help of machine learning. 

Now it is natural to ask one question: \textit{where to get the data?} Indeed, few institutions, not to mention individuals, independently hold data of many people with specificity high enough to train the complicated models, so data from different companies or institutions need to be combined to make it possible. On the other hand, due to the high specificity, institutions are reluctant in sharing their data because of the concerns for business interest or legal liability, and this poses a need for a technology to enable parties to use their data to jointly train a neural network with protection from the potential risk of data leakage.

Our work creates a prototype of privacy-preserving federated learning applications by combining the state of the art multi-party computation framework with a real machine learning use case. In our work, we illustrated the techniques for building a secure federated learning app, analyzed the security guarantees of our implementation and tested the performance of our prototype using experiments.

\subsection{Multi-party Computation}
Multi-party computation is a technique created by cryptography and distributed computing research community to enable multiple mutually distrust parties to perform computation on jointly held data. Formally, $N$ parties $p_1, p_2, ..., p_N$ each has an input $x_1, x_2, ..., x_N$ respectively. They want to collaborately compute a publicly known function $f$'s output on the inputs, i.e. $\text{out}=f(x_1, x_2, ..., x_N)$, without exposing any information about their own input other than that exposed by $\text{out}$ 

In general, MPC is achieved with either of two techniques, or a combination of them: garbled circuit or secret sharing. The ability to do MPC does not come for free. Instead, it often poses a substantially higher communication and computational cost than their trusted counterpart where privacy is not a concern. Many works have been done to reduce the cost of MPC for evaluating specific function or with additional assumptions. 

In our setting, we assume that the parties are honest-but-curious. In our model, all the parties behave honestly but they will attempt to discover other's input by examine the transcription of the execution passively, and we achieves privacy in the cryptographic sense even under $n-1$ corruption of the parties. In practice, this model provides data privacy guarantee against after-fact corruption, which covers majority of the security breaches. Moreover, this model reduces the burden of providing liveness and validating secret shares, and permits an efficient protocol. Notice that our prototype already incorporates SPDZ framework so it is impossible to modify the input data once the computation starts, but we believe additional efforts is required to make the framework provably secure under active attack such as selective message omission, and hence we only conservatively claim security under passive corruption model.

\subsection{iDash Privacy and Security Workshop 2019: Secure genome analytics competition}
iDash Privacy and Security Workshop is a reputable annually workshop on genome analytics where big institutions such as Google and IBM compete on. We choose to work with the workshop's topics because it represents the state-of-the-art problems in secure machine learning. 

Our work contributes to the topic `Secure Collaborative Training of Machine Learning Model' of the competition. We choose to work with the topics provided by the competition because it provides us with real data to start with and a clear metric to judge the result. The data used in this example consist of two sets of genome sketch labelled with cancer indicator. 12k(18k) genes were analyzed with 400(200) samples respectively. 
\section{Methodology and Technologies}

\section{Implementation}
\subsection{Requirement and Setup}
\textbf{Notice: It requires at least a setup with 12GB memory to run the code.}

\begin{listing}[H]
	\caption{Setup the runtime environment}
	\inputminted[frame=single,framesep=10pt,linenos]{bash}{1_prep.sh}
	\label{code_setup}
\end{listing}

Our experiment runs on 1 machine on the Tembusu Cluster with Intel E5-2620V3, 256GB DDR3 RAM, and CentOS 7.x.x. The code has been tested on Ubuntu 18.04 as well. You could use the code listed in Listing \ref{code_setup} to run in similar environments.  

Alternatively, you may run the prepared docker image with\\
\texttt{sudo docker run -it --net=host houruomu/cs6203 jupyter notebook --allow-root}

\subsection{Load the Data}
\begin{listing}[H]
	\caption{Load the data}
	\inputminted[frame=single,framesep=10pt,linenos]{python3}{load_data.py}
	\label{code_load}
\end{listing}
Our code snippet in Listing \ref{code_load} are the instructions that we used to load the data from the text document. In the text file, the first row and first column are data labels. Each column of the file corresponds to a data sample with rows being the SNPs values (i.e. the features). The code prepares the data into 2d numpy arrays with each row corresponding to a sample.

\subsection{Model Creation}
\begin{listing}[H]
	\caption{Define the model}
	\inputminted[frame=single,framesep=10pt,linenos]{python3}{torch_model.py}
	\label{code_model}
\end{listing}
Our model is adapted from a well-estabilished convolutional model for analyzing temporal data. The neural network has two data flows, on one flow there is only a fully connected layer with 64 outputs, and on the other flow a convolutional sub-network is repeatedly applied to generate a rich feature space. Then the two data flows are concatenated and 2 fully connected layers are used to get the binary output.

The code snippet in Listing \ref{code_model} illustrates our model definition. In \torch, the networks are defined as classes where in the \texttt{\_\_init\_\_} method the layers are defined and in \texttt{forward} method the operations to compose the layers are defined. The subnet class \texttt{Res1d} is defined with parameters \texttt{inSize, outSize, kernel, strides} to be used by the \texttt{Net} class to instatiate subnets in the layers definition. Notice that the \texttt{Net} class has a hidden parameter \texttt{dim} declared as a global variable, which corresponds to the feature space dimension of the input data.

\subsection{Model Training - plain model}
\begin{listing}[H]
	\caption{Train the model}
	\inputminted[frame=single,framesep=10pt,linenos]{python3}{train.py}
	\label{code_train}
\end{listing}
We use mini-batched stochastic gradient descent with binary cross entropy loss function to train the parameters. Based on experimental results, we choose a batch size of 30, learning rate of 0.001 and momentum of 0.9. The code for training is in Listing \ref{code_train}.


\end{document}